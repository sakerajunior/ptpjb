{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"green\"> https://bit.ly/ptpjb-2021-05</font><br><font color=\"blue\">05 - Introduction to Clustering Analysis</font></center>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">tau-data Indonesia</font><br>(C) Taufik Sutanto - 2021</center>\n",
    "<center><a href=\"https://tau-data.id\">https://tau-data.id</a> ~ <a href=\"mailto:taufik@tau-data.id\">taufik@tau-data.id</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Outline - Introduction to Clustering Analysis</font></center>\n",
    "\n",
    "* Pendahuluan Clustering ANalysis\n",
    "* Tujuan Clustering Analysis\n",
    "* k-Means Clustering\n",
    "* k-Medoids Clustering\n",
    "* Evaluasi internal k-Means\n",
    "* Evaluasi External Clustering\n",
    "* k-Means++\n",
    "* mini-Batch k-Means\n",
    "* Interpretasi & Visualisasi\n",
    "\n",
    "<img alt=\"\" src=\"images/K-Means-Clustering-in-Python.jpg\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade umap-learn\n",
    "!wget https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/tau_unsup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Modules untuk Notebook ini\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import umap, numpy as np, tau_unsup as tau, matplotlib.pyplot as plt, pandas as pd, seaborn as sns\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.metrics import silhouette_score as siluet\n",
    "from sklearn.metrics.cluster import homogeneity_score as purity\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI \n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "random_state = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/clustering_Quotes.png\"  style=\"height: 150px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Definisi Clustering</font></center>\n",
    "\n",
    "### <font color=\"green\">Clustering is as a process of finding group structures within data such that each instance within a group is similar to one another and dissimilar to instances in other groups [1]</font>\n",
    "\n",
    "<img src=\"images/clusters_objective.jpg\" style=\"height: 300px;\"/>\n",
    "\n",
    "\n",
    "[1]. Jain, A.K., Data clustering: 50 years beyond K-means. Pattern Recognition Letters, 2010. 31(8): p. 651-666."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Berbagai Pendekatan Clustering</font></center>\n",
    "\n",
    "<img src=\"images/tipe-clustering.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* **Hard Clustering**: Sebuah object hanya dapat dikelompokkan ke dalam satu group/cluster. Contoh k-Means.\n",
    "* **Soft Clustering**: Sebuah object dapat dikelompokkan ke lebih dari satu group/cluster. Contoh LDA (Topic Modelling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Aplikasi Clustering</font></center>\n",
    "\n",
    "Aplikasi Clustering secara garis besar: \n",
    "\n",
    "1. clustering untuk utility (e.g., data compression and indexing) and \n",
    "2. clustering untuk data understanding (e.g., menemukan struktur laten atau insight dari data) \n",
    "\n",
    "di ML/AI clustering biasanya termasuk aplikasi yang ke-2 \n",
    "\n",
    "### <center><font color=\"blue\">Tantangan Clustering</font></center>\n",
    "\n",
    "* Komputasi yang Tinggi\n",
    "* Evaluasi\n",
    "* Interpretasi\n",
    "* Sangat bergantung kepada domain knowledge\n",
    "\n",
    "<img src=\"images/clustering_efficiency.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Realworld Clustering Applications</font></center>\n",
    "\n",
    "<img src=\"images/clus_applications.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* Recommendation engines, Market segmentation\n",
    "* Social network analysis, Search result grouping\n",
    "* Medical imaging, Image segmentation\n",
    "* **Anomaly detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Algoritma k-Means</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/kmeans-algorithm.png\" style=\"width: 500px;\"/>\n",
    "<img alt=\"\" src=\"images/5_kmeans_Algorithm.png\" style=\"width: 500px;\" />\n",
    "\n",
    "* How it works: https://www.learndatasci.com/tutorials/k-means-clustering-algorithms-python-intro/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Diskusi k-Means Clustering</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/Clustering_kmeans_c.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* Apakah pengaruh menggunakan **centroid** dan algoritma ini terhadap bentuk cluster?\n",
    "* Apakah \"**bias**\" memilih algoritma clustering k-means ini?\n",
    "* \"* **k-Means tidak Robust terhadap outlier** *\" ... Mengapa? \n",
    "* Lalu apa yang sebaiknya dilakukan?\n",
    "* Optimasi di k-Means **bukan loss function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"\" src=\"images/meme-cartoon/meme clustering k-means.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Kita akan menggunakan 2 data: [1]. Iris dan [2]. Data untuk Studi Kasus (tentang Energy) - di bagian akhir\n",
    "# load the iris data\n",
    "df = sns.load_dataset(\"iris\")\n",
    "X = df[['sepal_length','sepal_width','petal_length','petal_width']]#.values\n",
    "C = df['species']#.values\n",
    "print(X.shape)\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# k-means: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "# \n",
    "k = 3\n",
    "km = cluster.KMeans(n_clusters=k, init='random', max_iter=300, tol=0.0001, random_state = 99)\n",
    "km.fit(X)\n",
    "# Hasil clusteringnya\n",
    "C_km = km.predict(X)\n",
    "p= sns.countplot(C_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# \"Label\" hasil clustering k-Means diatas.\n",
    "C_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"green\">Apakah perbedaan Label ini dengan hasil prediksi (klasifikasi)?</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/clustering_vs_classification_label.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* Sangat penting untuk dipahami dengan baik.\n",
    "* Keterangan lebih detail: https://tau-data.id/evaluasi-eksternal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Visualisasi Hasil Clustering?</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/meme-cartoon/k-Means-Visualization-joke.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* terdapat minimal 2 cara:\n",
    " - Melalui *dimensional Reduction* (DR) technique (perlu hati-hati dalam pemilihan algoritmanya).\n",
    " - Contoh DR yang cocok dan terkenal baik: t-SNE dan u-map Learn.\n",
    " - Melalui visualisasi \"parsial\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Visualisasi via Reduksi Dimensi</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X2D = umap.UMAP(n_neighbors=5, min_dist=0.3, random_state=random_state).fit_transform(X)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_km)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Visualisasi Parsial via Scatter Plot</font></center>\n",
    "\n",
    "* Memanfaatkan teknik yang sudah di bahas di data preprocessing dan visualisasi atas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['k-means'] = C_km\n",
    "g = sns.pairplot(df[['sepal_length','sepal_width','petal_length','petal_width','k-means']], \\\n",
    "                 hue=\"k-means\", diag_kind=\"hist\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Eksperimen Numerik (Studi Empiris) k-Means</font></center>\n",
    "\n",
    "* Hapus parameter \"random_state\" untuk memahami efek \"**randomized centroid**\".\n",
    "* Parameter n_jobs dapat digunakan untuk parallel processing.\n",
    "\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme cat experiment.jpg\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "k = 3\n",
    "km = cluster.KMeans(n_clusters=k, init='random', max_iter=300, tol=0.0001, n_jobs=-1, random_state = 99)\n",
    "km.fit(X)\n",
    "# Hasil clusteringnya\n",
    "C_km = km.predict(X)\n",
    "p= sns.countplot(C_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Hasil dan kesimpulan eksperimen sederhana diatas?</font></center>\n",
    "\n",
    "* Apakah akibat dari mengacak (randomized) centroid di awal algoritma?\n",
    "\n",
    "## <center><font color=\"red\">k-Means sangat tidak direkomendasikan untuk diaplikasikan di aplikasi nyata (production level)</font></center>\n",
    "\n",
    "## Mengapa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Better k-Means: k-Means++</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/km_vs_kmpp.gif\" style=\"height: 200px;\"/>\n",
    "\n",
    "* Original <em>k-means</em> memulai algoritmanya dengan mengacak centroid awal dan k-means tidak &quot;robust&quot; terhadap centroid awal ini (apa artinya?).\n",
    "* <strong>k-Means akan menghasilkan hasil yang berbeda-beda jika di-run beberapa kali!....</strong>\n",
    "* k-Means++ &quot;mengatasi&quot; hal ini:\n",
    "* inisialisasi centroid tidak random, tapi dengan menghitung probabilitas terbaik bagi centroid awal.\n",
    "* Keuntungan selain lebih robust, biasanya iterasi yang dibutuhkan jauh lebih sedikit ketimbang k-means biasa.\n",
    "* Reference :&nbsp;<a href=\"http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf\" target=\"_blank\">http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf</a>\n",
    "* image Source: https://medium.com/@phil.busko/animation-of-k-means-clustering-31a484c30ba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# k-means++ clustering http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "k=3\n",
    "kmPP = cluster.KMeans(n_clusters=k, init='k-means++', max_iter=300, tol=0.0001, n_jobs=-1, random_state = random_state)\n",
    "kmPP.fit(X)\n",
    "C_kmpp = kmPP.predict(X)\n",
    "\n",
    "sns.countplot(C_kmpp)\n",
    "C_kmpp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['k-means++'] = C_kmpp\n",
    "g = sns.pairplot(df[['sepal_length','sepal_width','petal_length','petal_width','k-means++']], \\\n",
    "                 hue=\"k-means++\", diag_kind=\"hist\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">k-Means untuk data yang besar: Mini-Batch k-Means</font></center>\n",
    "\n",
    "* Kompleksitas k-Means adalah $O(NkI)$ dimana $N$ jumlah data, $k$ jumlah cluster, dan $I$ jumlah iterasi.\n",
    "* <strong>Referensi</strong>: *Sculley, D. (2010, April). Web-scale k-means clustering. In&nbsp;<em>Proceedings of the 19th international conference on World wide web</em>&nbsp;(pp. 1177-1178). ACM.\n",
    "* Proposed by Google\n",
    "\n",
    "<img alt=\"\" src=\"images/5_minibatch.JPG\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MiniBatch k-Means http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html\n",
    "mbkm = cluster.MiniBatchKMeans(n_clusters=k, init='random', \\\n",
    "                               max_iter=300, tol=0.0001, batch_size = 100, random_state = random_state) \n",
    "mbkm.fit(X)\n",
    "C_mbkm = mbkm.predict(X)\n",
    "sns.countplot(C_mbkm)\n",
    "C_mbkm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['mini-k-means'] = C_mbkm\n",
    "g = sns.pairplot(df[['sepal_length','sepal_width','petal_length','petal_width','mini-k-means']], \\\n",
    "                 hue=\"mini-k-means\", diag_kind=\"hist\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">k-means VS MiniBatch k-Means?</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/kmeans_vs_mini_batch_kmeans.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Catatan penting Minibatch k-Means</font></center>\n",
    "\n",
    "* Seberapa besar/penting perbedaan hasil di mini-batch k-Means dan k-Means?\n",
    "* minibatch k-Means **tidak bisa parallel**.\n",
    "* parameter penting km = batch_size ... pada aplikasi sesungguhnya disarankan **minimal 3x jumlah cluster**\n",
    "* Dapat dipadukan (**hybrid**) dengan k-means++\n",
    "\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme machine learning hybrid mathematics algorithm.jpeg\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# MiniBatch k-Means++\n",
    "mbkmPP = cluster.MiniBatchKMeans(n_clusters=k, init='k-means++', \\\n",
    "                                 max_iter=300, tol=0.0001, random_state = random_state) \n",
    "mbkmPP.fit(X)\n",
    "C_mbkmPP = mbkmPP.predict(X)\n",
    "sns.countplot(C_mbkmPP)\n",
    "C_mbkmPP[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['mini-k-means++'] = C_mbkmPP\n",
    "g = sns.pairplot(df[['sepal_length','sepal_width','petal_length','petal_width','mini-k-means++']], \\\n",
    "                 hue=\"mini-k-means++\", diag_kind=\"hist\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Pentingnya memahami dengan Baik Makna Clustering</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/5_what_is_clustering.png\" style=\"height: 300px;\"/>\n",
    "\n",
    "* Tidak ada \"Ground Truth\" di Unsupervised Learning/Clustering. Sehingga tidak ada benar-salah, sehingga *tidak ada akurasi atau error*.\n",
    "* Salah satu \"Bias\" terbesar adalah algoritma clustering yang kita pilih.\n",
    "* Variabel kategorik pada algoritma k-means wajib di transformasi terlebih dahulu (misal one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Lalu bagaimana cara mengevaluasi hasil clustering?</font></center>\n",
    "\n",
    "* Biasa juga disebut sebagai nilai validasi.\n",
    "* Selain yang diberikan di gambar, di production level ada evaluasi lain (kolom ke-4 Canvas AI)\n",
    "* hati-hati dalam membandingkan algoritma clustering yang berbeda \"representasi cluster\".\n",
    "\n",
    "<img alt=\"\" src=\"images/tipe_evaluasi_clustering.png\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Evaluasi internal k-Means: inertia</font></center>\n",
    "\n",
    "* **Bukan Error!**, jangan sebut inertia sebagai **mse** atau semacamnya ... Mengapa?\n",
    "* Belum ada faktor \"inter distance\" ==> nanti **Silhouette Score**\n",
    "* image source: https://www.unioviedo.es/compnum/labs/new/kmeans.html\n",
    "\n",
    "<img alt=\"\" src=\"images/inertia_calc.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita lakukan ulang clustering k-Means sebelumnya\n",
    "k = 3\n",
    "km = cluster.KMeans(n_clusters=k, init='random', max_iter=300, tol=0.0001, n_jobs=-1, random_state = 99)\n",
    "km.fit(X)\n",
    "# Hasil clusteringnya\n",
    "C_km = km.predict(X)\n",
    "p= sns.countplot(C_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Perhatikan inertia menggunakan variabel \"km\" BUKAN C_km\n",
    "km.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Diskusi: Makna dan Manfaat inertia di k-Means</font></center>\n",
    "\n",
    "* Bagaimana memaknainya? \n",
    "* Apakah nilai diatas besar atau kecil?\n",
    "* Tidak ada clustering yang \"benar\"\n",
    "\n",
    "### <center><font color=\"green\">Catatan Penting dalam mengevaluasi Clustering secara internal:\n",
    "\n",
    "* Yang terpenting adalah interpretability/Informasi yang didapatkan (non-trivial information)\n",
    "* Internal metric tertentu hanya cocok untuk suatu algoritma tertentu juga, sehingga di Penelitian/Aplikasi di dunia professional jangan membandingkan 2 macam clustering dengan ukuran internal yang spesifik untuk metode clustering tertentu (misal Silhouette untuk k-Means).\n",
    "* Kleinberg, J. M. (2003). An impossibility theorem for clustering. In Advances in neural information processing systems (pp. 463-470).\n",
    "* Referensi 1: http://papers.nips.cc/paper/2340-an-impossibility-theorem-for-clustering.pdf\n",
    "* Referensi 2: https://core.ac.uk/download/pdf/34638775.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Optimal Number of Clusters? - Elbow Method -</font></center> \n",
    "\n",
    "* Menggunakan inertia\n",
    "* Rekomendasi ... **Bukan \"wajib\"** ==> Lalu apa yang lebih penting?\n",
    "* Best practice? --Membandingkan dengan jumlah cluster (k) di sekitar nilai optimal--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "distorsions, k1, kN = [], 2, 10\n",
    "for k in range(k1, kN):\n",
    "    kmeans = cluster.KMeans(n_clusters=k).fit(X)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "#fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(k1, kN), distorsions); plt.grid(True)\n",
    "plt.title('Elbow curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Evaluasi internal Silhouette Coefficient</font></center>\n",
    "\n",
    "* Mengapa membutuhkan silhouette jika sudah ada inertia?\n",
    "* Apa makna intuitive dari formula silhouette ini?\n",
    "\n",
    "<img alt=\"\" src=\"images/silhouette.png\" style=\"height: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tau.sil_based_optimal_km()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluasi : Internal . Contoh Silouette Coefficient ==> warning hanya cocok untuk k-means (centroid-based clustering)\n",
    "Hasil_Clustering = [C_km, C_kmpp, C_mbkm, C_mbkmPP]\n",
    "for res in Hasil_Clustering:\n",
    "    print(siluet(X,res), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Evaluasi Clustering Secara External</font></center>\n",
    "\n",
    "* Apa yang dimaksud evaluasi eksternal clustering?\n",
    "* Mengapa membutuhkan Evaluasi Eksternal\n",
    "* Sebelumnya kita perlu memahami konsep \"**True/False ~ Positive/Negative**\"\n",
    "\n",
    "<img alt=\"\" src=\"images/meme-cartoon/confusion-matrix-meme.jpg\" style=\"height: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"green\">Memahami Evaluasi Eksternal dengan baik</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/clustering_vs_classification_label.png\" style=\"height: 200px;\"/>\n",
    "\n",
    "* contoh Apa True/False ~ Positif/Negative di contoh diatas\n",
    "* **True Positive (TP)**:\n",
    " - dua objek (misal d1 dan d2) berdasarkan hasil sebuah algoritma clustering berada di kelompok yang sama, dan “menurut GT” memang keduanya benarberada di kelompok yang sama. Misal di GT label d1 dan d2 = {1, 1} dan di clustering = {3, 3}.\n",
    "* **True Negative (TN)**:\n",
    " - d1 dan d2 tidak dikelompokan ke dalam satu cluster, dan memang menurut GT mereka berdua ndak berjodoh. Misal di GT label d1 dan d2 = {1,2} dan di clustering = {7, 8}\n",
    "* **False Positive (FP)**:\n",
    "- d1 dan d2 menurut GT harusnya berada di kelompok yang berbeda, tapi karena satu dan lain hal mereka dikelompokkan ke 2 cluster yang sama oleh algoritma clusternya. Ini kayak dijodohin paksa gitu deh Gan … :v …. Misal di GT label d1 dan d2 = {1, 2} dan di hasil clustering = {5, 5}\n",
    "* **False Negative (FN)**:\n",
    " - d1 dan d2 menurut GT harusnya di cluster sama, tapi dipisahkan oleh jarak dan waktu,… eh salah… maksudnya oleh hasil clusteringnya (kebalikan FP). Misal di GT label d1 dan d2 = {2, 2} dan di hasil clustering = {5, 7}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">NMI & $F-\\beta Score$</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/Prec-Rec-FScore-Rnd_idx.png\" style=\"height: 200px;\"/>\n",
    "\n",
    "* Hati-hati karena perbedaan makna TP, FP, TN, & FN kelak di klasifikasi NMI dan $F-\\beta Score$ akan dihitung secara berbeda (beda algoritma, namun nama metricnya sama).\n",
    "* Jika dilihat sekilas, apa beda RI dan  $F-\\beta Score$?\n",
    "* $\\beta=1$ artinya presisi sama pentingnya dengan recall.\n",
    "* Apa makna presisi dan recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Presisi VS Recall</font></center>\n",
    "\n",
    "* **Precision**: jika kita perhatikan dari rumusnya, P hanya menggunakan ukuran apakah hasil clustering/SSC-nya positive atau tidak. Maka Precision bermakna ketepatan dalam pengambilan keputusan. Misal di Information Retrieval (IR), ini bermakna berapa banyak hasil search yang tepat (relevant) yang keluar di hasil query.\n",
    "* **Recall**: Kalau dilihat di rumusnya hanya ada TP dan FN lalu kalau masih ingat apa itu FN, maka tidak akan terlalu susah memaknai recall. Bayangkan FN=0 bagaimana nilai recall, lalu bayangkan FN besar bagaimana nilai recallnya? Recall dapat dimaknai sebagai \"kemurnian keputusan (prediksi di klasifikasi) positif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Purity in External CLustering Evaluation</font></center>\n",
    "\n",
    "* Perlu nilai \"Golden Standard\" untuk pemasangan (mapping) antara label mayoritas dan gold standard-nya.\n",
    "* \"Analogi\" (bukan error) dengan akurasi.\n",
    "\n",
    "<img alt=\"\" src=\"images/cluster_purity_external_evaluation.png\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Berbagai Macam Evaluasi Clustering: Internal & External</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/5_Clustering_evaluation.jpg\"  style=\"height: 400px;\"/>\n",
    "\n",
    "* ingat di industri/dunia nyata ada tambahan evaluasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Bagaimana dengan evaluasi External?\n",
    "# \"C\" adalah golden standard dalam hal ini misal spesies bunga iris menurut para ahli biologi\n",
    "for res in Hasil_Clustering:\n",
    "    print(purity(C,res), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluasi External NMI \n",
    "for res in Hasil_Clustering:\n",
    "    print(NMI(C,res), end=', ')\n",
    "# untuk F-Score ada juga code dan penjelasannya di blog post di atas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Cara menarik kesimpulan dari k-Means: Interpretasi & Penamaan Cluster</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/cluster_interpretation_and_labelling.png\"  style=\"height: 300px;\"/>\n",
    "\n",
    "* Mudahnya diartikan sebagai penamaan cluster.\n",
    "* Karena k-Means menggunakan centroid sebagai representasi cluster, maka interpretasi berdasarkan nilai-nilai di seluruh centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmPP.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluasi sebenarnya tidak terlalu penting di Unsupervised learning.\n",
    "# inilah yang membedakan \"clustering\" dan \"clustering Analysis\"\n",
    "# yang lebih penting adalah interpretasi, tapi Bagaimana?\n",
    "# contoh k-means++\n",
    "\n",
    "cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "dfC = pd.DataFrame(kmPP.cluster_centers_, columns=cols)\n",
    "dfC['cluster'] = dfC.index\n",
    "\n",
    "pd.plotting.parallel_coordinates(dfC, 'cluster', color=('r', 'g', 'b'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Tips Penting Penggunaan k-Means</font></center>\n",
    "\n",
    "* Hati-hati faktor **skala data** ==> Normalisai/Standardized. Apa pengaruhnya?\n",
    "* Hati-hati asumsi **topologi data** di k-means.\n",
    "* Sangat **tidak disarankan untuk data tidak terstruktur** dan berskala besar. Kalau datanya tidak besar cukup ganti jarak euclid dengan similarity Cosine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul 05 - Introduction to Clustering Analysis</font></center>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/5_saveme_clustering.jpg\" style=\"height: 300px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
