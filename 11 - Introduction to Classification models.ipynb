{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"green\"> https://bit.ly/ptpjb-2021-11</font></center>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://bit.ly/ptpjb-2021-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">11 - Introduction to Classification models</font></center>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">tau-data Indonesia</font><br>(C) Taufik Sutanto - 2021</center>\n",
    "<center><a href=\"https://tau-data.id\">https://tau-data.id</a> ~ <a href=\"mailto:taufik@tau-data.id\">taufik@tau-data.id</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Outline: Introduction to Classification models</font></center>\n",
    "\n",
    "* Pendahuluan Model Klasifikasi\n",
    "* k-Nearest Neighbour\n",
    "* Evaluasi Dasar\n",
    "* Underfitting-Overfitting\n",
    "* Cross-validasi\n",
    "* Regresi Logistik\n",
    "* Naive Bayes\n",
    "* Decision Tree dan Random Forest\n",
    "\n",
    "<img style=\"undefined: undefined;\" src=\"images/meme-cartoon/meme_08-Classification_Prediction.png\" width=\"420\" height=\"236\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">  Variabel target (dependent) dan prediktor (independent)</font></center>\n",
    "\n",
    "<img style=\"undefined: undefined;\" src=\"images/Dependent-Independent.png\" width=\"294\" height=\"197\" />\n",
    "\n",
    "* **Variable Target**: adalah satu atau lebih variabel yang dipengaruhi oleh satu atau lebih variabel yang lain.\n",
    "Contoh: Variabel gaji dipengaruhi oleh variabel lama kerja, pangkat serta jabatan seorang pegawai.\n",
    "Variable \n",
    "* **Variabel Prediktor** : adalah satu atau lebih variabel yang mempengaruhi satu atau lebih variabel yang lain.\n",
    "Contoh: Variabel kecepatan mempengaruhi waktu tempuh perjalanan.\n",
    "* **Variabel Kontrol**: adalah variabel/elemen yang nilainya tetap (konstan), biasanya pada suatu eksperimen untuk menguji hubungan antara variabel target dan prediktor.\n",
    "Contoh: Penggunaan Placebo (obat palsu) pada penelitian/eksperimen efek suatu obat tertentu.\n",
    "* **Variable Confounding** Biasa juga disebut sebagai “variabel ketiga” atau “variabel mediator”, yaitu suatu (extra*) variabel yang mempengaruhi hubungan antara variabel dependent dan independent.\n",
    "Contoh: Pada penelitian tentang dampak olahraga (prediktor) terhadap berat badan (target), maka variabel lain seperti pola makan dan usia juga akan mempengaruhi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Pentingnya Domain Knowledge</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme-dependent-independent var.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Bentuk Struktur Data Masalah Klasifikasi</font></center>\n",
    "\n",
    "* Klasifikasi adalah permasalahan meng-kategorisasikan sekelompok observasi baru ke sekumpulan kategori (kelas) yang ada sebelumnya. \n",
    "* Mengacu ke Gambar dibawah, klasifikasi digunakan jika variabel target bertipe kategorik dan prediktornya satu atau lebih variabel numerik dan-atau kategorik. \n",
    "\n",
    "<p><img src=\"images/iris_flower.png\" alt=\"\" width=\"414\" height=\"310\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Aplikasi Model Klasifikasi</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/machine learning classification applications.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Berbagai Pendekatan ke Klasifikasi</font></center>\n",
    "\n",
    "* Terdapat cukup banyak model klasifikasi yang dapat digunakan, mulai dari yang klasik seperti Linear Discriminant Analysis (LDA) dan regresi logistik, lalu ke moderate seperti SVM (support vector machines), decision tree dan neural network (jaringan syaraf tiruan), sampai yang lebih terkini seperti random forest,  dan deep learning. \n",
    "* Masing-masing memiliki kelebihan dan kekurangan masing-masing bergantung pada bagaimana model/algoritmanya. \n",
    "\n",
    "<img alt=\"\" src=\"images/Berbagai_Macam_Pendekatan_Klasifikasi.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Induktif Bias Sebagai Dasar Penting untuk Mengerti SEMUA model Data Science dan Machine Learning</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/inductive_biases.png\" />\n",
    "\n",
    "image source: https://sgfin.github.io/2020/06/22/Induction-Intro/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Permasalahan Klasifikasi</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/masalah_klasifikasi.png\" /></p>\n",
    "\n",
    "* Misal diberikan permasalahan terdapat dua buah kategori orange dan ungu seperti di gambar.\n",
    "* Setiap titik di ganmbar adalah entitas dari data yang terdiri dari beberapa variabel.\n",
    "* Jika diberikan titik baru (warna putih), maka masalah klasifikkasi adalah kemudian menggolongkan data baru ini ke kategori titik Orange atau Ungu.\n",
    "\n",
    "## <font color=\"green\">Mari membahas teori Bersamaan Dengan Implementasinya</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import graphviz, pandas as pd, matplotlib.pyplot as plt\n",
    "import time, numpy as np, seaborn as sns\n",
    "from sklearn import  tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from dtreeviz.trees import *\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kasus Sederhana Klasifikasi 01: Klasifikasi Spesies Bunga Iris</font></center>\n",
    "\n",
    "* Data klasifikasi bunga Iris sebagai studi kasus sederhana\n",
    "* Link data: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "* Paper sumber data: Fisher,R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950). \n",
    "* Masalah klasifikasinya adalah mengklasifikasikan jenis Bunga Iris berdasarkan bentuk (e.g. panjang dan lebar) bunga.\n",
    "\n",
    "<img src=\"images/iris_flower.png\" alt=\"\" width=\"503\" height=\"377\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data Bunga Iris\n",
    "data = sns.load_dataset(\"iris\")\n",
    "print(data.shape)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['species'] = data['species'].astype('category')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplikasi = \", data.duplicated().sum())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep=\"first\", inplace=True)\n",
    "print(\"Duplikasi = \", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.pairplot(data, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita membuat dataframe baru, hati-hati jika datanya besar.\n",
    "df1 = data[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y1 = data['species']\n",
    "df1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kasus Sederhana Klasifikasi 02: Efisiensi Energy Gedung</font></center>\n",
    "\n",
    "* Terdapat 12 Macam bentuk Gedung disimulasikan dalam EcoTect. Gedung-gedung tersebut berbeda menurut beberapa parameter (e.g. glazing area, the glazing area distribution, and the orientation). \n",
    "* Dari parameter tadi terdapat 768 bentuk gedung dan 8 variabel.\n",
    "* aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.\n",
    "* Link data: https://archive.ics.uci.edu/ml/datasets/energy+efficiency\n",
    "* Paper sumber data: A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012\n",
    "\n",
    "<img src=\"images/buildings-by-calibrated-simulation.png\" alt=\"\" width=\"503\" height=\"377\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = \"data/building-energy-efficiency-ENB2012_data.csv\"\n",
    "\n",
    "try: # Running Locally, yakinkan \"file_\" berada di folder \"data\"\n",
    "    data = pd.read_csv(file_, error_bad_lines=False, low_memory = False, encoding='utf8')\n",
    "except: # Running in Google Colab\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/ptpjb/master/{file_}\n",
    "    data = pd.read_csv(file_, error_bad_lines=False, low_memory = False, encoding='utf8')\n",
    "print(data.shape)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">PreProcessing & Minor EDA</font></center>\n",
    "\n",
    "* Preprocessing apa yang diperlukan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())\n",
    "print(set(data[\"orientation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['orientation'] = data['orientation'].astype('category')\n",
    "data['heat-cat'] = data['heat-cat'].astype('category')\n",
    "data['cool-cat'] = data['cool-cat'].astype('category')\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplikasi = \", data.duplicated().sum())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning agak lambat karena plot yg di generate cukup banyak \n",
    "col_ = \"surface-area wall-area roof-area overall-height heat-cat\".split()\n",
    "p = sns.pairplot(data[col_], hue=\"heat-cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge of the prediction\n",
    "print(data[\"heat-cat\"].value_counts())\n",
    "p = sns.countplot(x=\"heat-cat\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"orientation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding, lalu menggabungkan dengan data awal\n",
    "dum_ = pd.get_dummies(data['orientation'], prefix='ori')\n",
    "data = pd.concat([data, dum_], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2A = data[['compactness', 'surface-area', 'wall-area', 'roof-area', \\\n",
    "            'overall-height','orientation','glazing-area','glazing-dist']]\n",
    "df2B = data[['compactness', 'surface-area', 'wall-area', 'roof-area', \\\n",
    "            'overall-height','ori_2', 'ori_3', 'ori_4', 'ori_5','glazing-area','glazing-dist']]\n",
    "y2 = data['heat-cat']\n",
    "df2B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Sebelum dimulai Data Kita Pisahkan Menjadi Train dan Test: Mengapa?</font></center>\n",
    "\n",
    "<p><img src=\"images/data train val test separation.png\" width=\"416\" height=\"327\" /></p>\n",
    "\n",
    "* Bagaimana membagi Porsi Train VS Porsi Test Data?\n",
    "* <font color=\"red\">**Hati-hati** dalam memisahkan data Train dan Test: Mengapa?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_train, df1_test, y1_train, y1_test = train_test_split(df1, y1, test_size=0.3, random_state=33)\n",
    "df2A_train, df2A_test, y2_train, y2_test = train_test_split(df2A, y2, test_size=0.3, random_state=33) #No One-Hot\n",
    "df2B_train, df2B_test, y2_train, y2_test = train_test_split(df2B, y2, test_size=0.3, random_state=33) # One-Hot\n",
    "print(df1_train.shape, df1_test.shape)\n",
    "print(df2A_train.shape, df2A_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">k-Nearest Neighbour</font></center>\n",
    "\n",
    "<ul>\n",
    "<li>Classifier yang paling sederhana, namun dapat juga digunakan untuk regresi (dan bahkan clustering).</li>\n",
    "<li>Sering disebut sebagai <u><strong>Instance based Learner</strong></u></li>\n",
    "<li>Tidak memiliki \"persamaan\", pendekatannya lebih ke algoritmik berdasarkan konsep jarak/similarity</li>\n",
    "<li>Mirip konsep DBSCAN</li>\n",
    "</ul>\n",
    "<p><img src=\"images/6_kNN.JPG\" alt=\"\" width=\"702\" height=\"296\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">k-NN Neighbour Size & Weights</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/k-NN_neighbour_size.png\" /></p>\n",
    "\n",
    "<ul>\n",
    "\t<li><big><strong>Uniform</strong></big>: all points in each neighborhood are weighted equally.</li>\n",
    "\t<li><big><strong>Distance</strong></big>: closer neighbors of a query point have a greater influence than the neighbors further away.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Similarity VS Distance</font></center>\n",
    "\n",
    "<p><img src=\"images/other_Distance.gif\" alt=\"\" width=\"498\" height=\"236\" /></p>\n",
    "\n",
    "## Similarity explained in plain terms and its application in Python\n",
    "### http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kelebihan dan Kekurangan</font></center>\n",
    "\n",
    "<dl>\n",
    "\t<dt><strong>Pros:</strong></dt>\n",
    "\t<dd>\n",
    "\t<ul>\n",
    "\t\t<li>Relatif cepat (efisien) untuk data yang tidak terlalu besar</li>\n",
    "\t\t<li>Sederhana, mudah untuk diimplementasikan</li>\n",
    "\t\t<li>Mudah untuk di modifikasi: Berbagai macam formula jarak/similaritas</li>\n",
    "\t\t<li>Menangani data Multiclass dengan mudah</li>\n",
    "\t\t<li>Akurasi cukup baik jika data representatif</li>\n",
    "\t</ul>\n",
    "\t</dd>\n",
    "\t<dt><strong>Cons:</strong></dt>\n",
    "\t<dd>\n",
    "\t<ul>\n",
    "\t\t<li>Menemukan&nbsp;nearest neighbours tidak efisien untuk data besar</li>\n",
    "\t\t<li>Storage of data</li>\n",
    "\t\t<li>Meyakinkan rumus jarak yang tepat</li>\n",
    "\t</ul>\n",
    "\t</dd>\n",
    "</dl>\n",
    "\n",
    "## <font color=\"green\">Aplikasi di Python</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "n_neighbors = 3\n",
    "weights = 'distance'\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "kNN.fit(df1_train, y1_train)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi dengan k-NN\n",
    "y_kNN1 = kNN.predict(df1_test)\n",
    "y_kNN1[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "kNN.fit(df2B_train, y2_train)\n",
    "y_kNN2 = kNN.predict(df2B_test)\n",
    "y_kNN2[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Seberapa Baik Hasil Prediksi Ini?: Evaluation Metrics</font></center>\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "    \n",
    "<center><img alt=\"\" src=\"images/classification_metrics.png\" style=\"height: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Confusion Matrix</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/confusion_matrix.png\" /></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>sensitivity, recall, hit rate, or true positive rate (TPR)</li>\n",
    "\t<li>precision or positive predictive value (PPV)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/ex-F1-Score.png\" /></p>\n",
    "* Yang mana kategori yang \"positif\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/F-beta-Score.png\" /></p>\n",
    "\n",
    "* $0\\leq F\\leq 1$, 1 optimal value\n",
    "* $0\\leq\\beta< \\inf$\n",
    "* beta < 1 lends more weight to precision, \n",
    "* beta > 1 favors recall \n",
    "* beta -> 0 considers only precision \n",
    "* beta -> inf only recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Micro VS Macro Metric</font></center>\n",
    "\n",
    "<p><img src=\"images/micro-vs-macro-f-score.png\" alt=\"\" width=\"790\" height=\"244\" /></p>\n",
    "\n",
    "### <font color=\"green\">Pada 2 kasus diatas:</font>\n",
    "* sebaiknya Micro atau macro?\n",
    "* Mana yang lebih penting Presisi atau Recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kasus 01 - Bunga Iris: kNN\")\n",
    "print(confusion_matrix(y1_test, y_kNN1))\n",
    "print(classification_report(y1_test, y_kNN1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kasus 02 - Building Energy\")\n",
    "print(confusion_matrix(y2_test, y_kNN2))\n",
    "print(classification_report(y2_test, y_kNN2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Cross Validation</font></center>\n",
    "\n",
    "* Evaluasi yang kita lakukan belum cukup valid/objektif ... Mengapa?\n",
    "\n",
    "<img alt=\"\" src=\"images/6_Cross_validation.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# Perhatikan variabelnya, kita sekarang menggunakan seluruh data\n",
    "# namun sebaiknya hanya Train data (jika datanya cukup besar)\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "mulai = time.time()\n",
    "scores_kNN = cross_val_score(kNN, df1, y1, cv=10)\n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy k-NN: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_kNN.mean(), scores_kNN.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi model dengan lebih baik lagi\n",
    "df_ = pd.DataFrame({'kNN': scores_kNN})\n",
    "p = sns.boxplot(data = df_)\n",
    "min(scores_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Klasifikasi dengan Model Regresi Logistik</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/klas_regLogistik.png\" /></p>\n",
    "\n",
    "* Mencari garis lurus yang sedemikian sehingga kesalahan prediksinya sekecil mungkin (lihat gambar)\n",
    "* Awalnya regresi logistik adalah metode klasifikasi binary: membedakan antara 2 kelas atau kategori.\n",
    "* Masalah klasifikasi binary contohnya memprediksi seseorang terkena \"kanker\" atau \"tidak kanker\", kanker jinak/ganas, fraud atau bukan fraud (pada transaksi keuangan), negatif/positif dalam sentimen analisis, dsb.\n",
    "* Regresi logistik adalah pengembangan dari model regresi liniear, namun di konversi ke masalah klasifikasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Regresi Logistik</font></center>\n",
    "\n",
    "<p><img src=\"images/reg_to_log.png\" alt=\"\" width=\"591\" height=\"298\" /></p>\n",
    "\n",
    "* http://www.saedsayad.com/logistic_regression.htm\n",
    "* Makna fungsi logarithm?\n",
    "* Konsekuensi dari rumus $\\beta$ diatas?\n",
    "* Asumsi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kaitan Regresi Logistik dan Neural Network/Deep Learning</font></center>\n",
    "\n",
    "<p><img src=\"images/logReg_NN_DL.png\" alt=\"\" width=\"262\" height=\"263\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img src=\"images/Fungsi_Sigmoid_.png\" alt=\"\" width=\"624\" height=\"416\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Kelebihan dan Kekurangan Regresi Logistik</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/LogReg_When2use.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglog = LogisticRegression().fit(df1_train, y1_train)\n",
    "y_reglog1 = reglog.predict(df1_test)\n",
    "print(\"Kasus 01 - Bunga Iris: Regresi Logistik\")\n",
    "print(confusion_matrix(y1_test, y_reglog1))\n",
    "print(classification_report(y1_test, y_reglog1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulai = time.time()\n",
    "scores_regLog = cross_val_score(reglog, df1, y1, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "print(\"Accuracy Regresi Logistik: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_regLog.mean(), scores_regLog.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi & membandingkan model dengan lebih baik lagi\n",
    "df_ = pd.DataFrame({'kNN': scores_kNN, 'RegLog': scores_regLog})\n",
    "p = sns.boxplot(data = df_)\n",
    "min(scores_kNN),min(scores_regLog) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Naive Bayes Classifier</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/naive_bayes.png\" style=\"width: 400px ; height: 220px\" />\n",
    "\n",
    "* P(x) konstan, sehingga bisa diabaikan.\n",
    "* Asumsi terkuatnya adalah independensi antar variabel prediktor (sehingga dikatakan &quot;Naive&quot;)\n",
    "* Klasifikasi dilakukan dengan menghitung probabilitas untuk setiap kategori ketika diberikan data x = (x1,x2,...,xm)\n",
    "* Variasi NBC adalah bagaimana P(c|x) dihitung, misal dengan distribusi Gaussian (Normal) - sering disebut sebagai Gaussian Naive Bayes (GNB):\n",
    "\n",
    "<img alt=\"\" src=\"images/Gaussian.png\" style=\"width: 303px ; height: 50px\" />\n",
    "\n",
    "* Self readings: \n",
    " * https://www.saedsayad.com/naive_bayesian.htm\n",
    " * https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Kelebihan dan Kekurangan Naive Bayes Classifier</font></center>\n",
    "\n",
    "<p><em><strong>Pros:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Cepat dan mudah di implementasikan</li>\n",
    "\t<li>Cocok untuk permasalahan multiclass</li>\n",
    "\t<li>Jika asumsi terpenuhi (independent) biasanya performanya cukup baik dan membutuhkan data (training) yang lebih sedikit.</li>\n",
    "\t<li>Biasanya baik digunakan untuk prediktor kategorik, untuk numerik NBC mengasumsikan distribusi normal (terkadang tidak terpenuhi)&nbsp;</li>\n",
    "</ul>\n",
    "\n",
    "<p><em><strong>Cons:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Jika di test data memuat kategori yang tidak ada di training data ( ==&gt; probabilitas = 0). Sering disebut sebagai masalah&nbsp; &ldquo;Zero Frequency&rdquo;.&nbsp;</li>\n",
    "\t<li>Asumsi yang sangat kuat (independen antar prediktor).</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Naive Bayes di Social Media Analytics</font></center>\n",
    "\n",
    "* Sentiment Analysis\n",
    "\n",
    "<p><img alt=\"\" src=\"images/SNA_Graph_Types.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nbc = gnb.fit(df1_train, y1_train)\n",
    "y_nb1 = nbc.predict(df1_test)\n",
    "\n",
    "print(confusion_matrix(y1_test, y_nb1))\n",
    "print(classification_report(y1_test, y_nb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulai = time.time()\n",
    "scores_nb = cross_val_score(nbc, df1, y1, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "print(\"Accuracy Naive Bayes: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_nb.mean(), scores_nb.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi & membandingkan model dengan lebih baik lagi\n",
    "df_ = pd.DataFrame({'kNN': scores_kNN, 'RegLog': scores_regLog, 'NaiveBys':scores_nb})\n",
    "p = sns.boxplot(data = df_)\n",
    "min(scores_kNN), min(scores_regLog), min(scores_nb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Decision Tree Analogi</font></center>\n",
    "<img alt=\"\" src=\"images/meme-cartoon/6_DT_meme.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Decision Tree (Pohon Keputusan)</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/tree_plot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Decision Tree (Pohon Keputusan): Contoh Aplikasi</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/6_DT.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Teori Decision Tree : Entropy Formula</font></center>\n",
    "<p><img alt=\"\" src=\"images/Entropy.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Teori Decision Tree : Entropy Calculation</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/Contoh_Entropy.png\" style=\"width: 469px; height: 339px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Teori Decision Tree : Gain Formula</font></center>\n",
    "<p><img alt=\"\" src=\"images/Information_Gain.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Teori Decision Tree : Gain Calculation</font></center>\n",
    "\n",
    "<p><img style=\"undefined: undefined;\" src=\"images/Contoh_Gain.png\" alt=\"\" width=\"527\" height=\"370\" /></p>\n",
    "<ul>\n",
    "<li>Contoh Lain: <a href=\"http://www.saedsayad.com/decision_tree.htm\" target=\"_blank\" rel=\"nofollow noopener\">http://www.saedsayad.com/decision_tree.htm</a></li>\n",
    "<li>Ross Quinlan Website: <a href=\"https://www.rulequest.com/Personal/\" target=\"_blank\" rel=\"nofollow noopener\">https://www.rulequest.com/Personal/</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Teori Decision Tree : Information theory</font></center>\n",
    "\n",
    "<p><img src=\"images/dec_Tree_Theory.png\" alt=\"\" width=\"594\" height=\"334\" /></p>\n",
    "<ul>\n",
    "<li>Alternative to Information Gain : Gini Index (CART): <a href=\"https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1\" target=\"_blank\" rel=\"nofollow noopener\">https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Pengaruh \"ketinggian\" tree terhadap bentuk model</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/Dec_Tree_Asumsi_Depth.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Decision Tree (Pohon Keputusan): Kelebihan & Kekurangan</font></center>\n",
    "\n",
    "<p><u><strong>When to use:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Target : Binomial/nominal.</li>\n",
    "\t<li>Predictors (input): binomial, nominal, and-or interval (ratio).</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Advantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Fast and embarrassingly parallel.</li>\n",
    "\t<li>Tanpa iterasi, cocok untuk&nbsp;Big Data technology (e.g. Hadoop)[map-reduce friendly]</li>\n",
    "\t<li>Interpretability</li>\n",
    "\t<li>Robust terhadap outliers &amp; missing values</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Disadvantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Non probabilistic (ad hoc heuristic) +/-</li>\n",
    "\t<li>Target dengan banyak kelas</li>\n",
    "\t<li>Sensitive (instability)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Decision Tree: http://scikit-learn.org/stable/modules/tree.html\n",
    "DT = tree.DecisionTreeClassifier() \n",
    "# Sengaja menggunakan default parameter, (Hyper)parameter Optimization akan dibahas kemudian\n",
    "DT = DT.fit(df1_train, y1_train)\n",
    "y_DT1 = DT.predict(df1_test)\n",
    "\n",
    "print(confusion_matrix(y1_test, y_DT1))\n",
    "print(classification_report(y1_test, y_DT1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Varible importance - Salah satu kelebihan Decision Tree\n",
    "DT.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Kelebihan lain Decision Tree yang tidak dimiliki model lain\n",
    "# \"WARNING\" \n",
    "# 1. tidak bisa dijalankan di Google Colab\n",
    "# 2. membutuhkan software \"graphViz\" + setting system variabel\n",
    "# caranya ada disini: https://stackoverflow.com/questions/49471867/installing-graphviz-for-use-with-python-3-on-windows-10\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(DT, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\") \n",
    "var_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "categories = ['Setosa', 'VersiColor', 'Virginica']\n",
    "dot_data = tree.export_graphviz(DT, out_file=None, \n",
    "                         feature_names = var_names,  \n",
    "                         class_names=categories,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulai = time.time()\n",
    "scores_dt = cross_val_score(DT, df1, y1, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "print(\"Accuracy Decision Tree: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_dt.mean(), scores_dt.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi & membandingkan model dengan lebih baik lagi\n",
    "df_ = pd.DataFrame({'kNN': scores_kNN, 'RegLog': scores_regLog, 'NaiveBys':scores_nb, \"DecTree\":scores_dt})\n",
    "p = sns.boxplot(data = df_)\n",
    "min(scores_kNN), min(scores_regLog), min(scores_nb), min(scores_dt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Curse of Dimensionality & Random Forest</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/5_RandomForest.png\" style=\"width: 592px; height: 444px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Mari coba perbaiki dengan Random Forest\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(df1_train, y1_train)\n",
    "y_rf1 = rf.predict(df1_test)\n",
    "\n",
    "print(confusion_matrix(y1_test, y_rf1))\n",
    "print(classification_report(y1_test, y_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varible importance\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(df1.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(df1.shape[1]), importances[indices],color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(df1.shape[1]), indices)\n",
    "plt.xlim([-1, df1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulai = time.time()\n",
    "scores_rf = cross_val_score(rf, df1, y1, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "print(\"Accuracy Random Forest: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_rf.mean(), scores_rf.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi & membandingkan model dengan lebih baik lagi\n",
    "df_ = pd.DataFrame({'kNN': scores_kNN, 'RegLog': scores_regLog, 'NaiveBys':scores_nb, \"DecTree\":scores_dt, \"Forest\": scores_rf})\n",
    "p = sns.boxplot(data = df_)\n",
    "min(scores_kNN), min(scores_regLog), min(scores_nb), min(scores_dt), min(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"green\">Model yang lebih kompleks belum tentu lebih baik, Mengapa?</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Results untuk digunakan di module selanjutnya\n",
    "df_.to_csv(\"data/df_Module-11.csv\", encoding='utf8', index=False)\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul 11 - Introduction to Classification models</font></center>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/Meme-on-Machine-Learning-accuracy.jpg\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
