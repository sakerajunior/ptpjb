{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"green\"> https://bit.ly/ptpjb-2021-12</font></center>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://bit.ly/ptpjb-2021-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">12 - Advanced prediction in Machine Learning</font></center>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">tau-data Indonesia</font><br>(C) Taufik Sutanto - 2021</center>\n",
    "<center><a href=\"https://tau-data.id\">https://tau-data.id</a> ~ <a href=\"mailto:taufik@tau-data.id\">taufik@tau-data.id</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Outline: Model Klasifikasi Lanjutan</font></center>\n",
    "\n",
    "* Support Vector Machines\n",
    "* Evaluasi revisited: Underfitting & Overfitting\n",
    "* Pipelining & Parameter Optimization\n",
    "* Proper Model Selection\n",
    "* Ensemble Learning\n",
    "* Imbalance Learning\n",
    "* Studi Kasus\n",
    "\n",
    "<img src=\"images/meme-cartoon/meme model on train and test data.jpg\" height=\"250\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Modules\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "import time, numpy as np, seaborn as sns\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn import  tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulai dengan Load Data dari Modul sebelumnya terlebih dahulu\n",
    "file_ = \"data/data_Module-11.pckl\"\n",
    "try: # Running Locally, yakinkan \"file_\" berada di folder \"data\"\n",
    "    f = open(file_, 'rb')\n",
    "    data = pickle.load(f); f.close()\n",
    "except: # Running in Google Colab\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/ptpjb/master/{file_}\n",
    "    f = open(file_, 'rb')\n",
    "    data = pickle.load(f); f.close()\n",
    "\n",
    "df_, df1, y1, df2A, df2B, y2 = data\n",
    "df_.shape, df_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akan sama dengan module sebelumnya karena nilai SEED sama.\n",
    "df1_train, df1_test, y1_train, y1_test = train_test_split(df1, y1, test_size=0.3, random_state=33)\n",
    "df2A_train, df2A_test, y2_train, y2_test = train_test_split(df2A, y2, test_size=0.3, random_state=33) #No One-Hot\n",
    "df2B_train, df2B_test, y2_train, y2_test = train_test_split(df2B, y2, test_size=0.3, random_state=33) # One-Hot\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Support Vector Machine (SVM)</font></center>\n",
    "\n",
    "Misal data dinyatakan sebagai berikut:\n",
    "$\\{(\\bar{x}_1,y_1),...,(\\bar{x}_n,y_n)\\}$, dimana $\\bar{x}_i$ adalah\n",
    "input pattern untuk data ke $i^{th}$ dan $y_i$ adalah nilai target yang diinginkan. Kategori\n",
    "(class) direpresentasikan dengan $y_i=\\{-1,1\\}$. Sebuah **bidang datar (hyperplane)** yang memisahkan kedua kelas ini (\"linearly separable\") adalah:\n",
    "$$ \\bar{w}'\\bar{x} + b=0 $$\n",
    "dimana $\\bar{x}$ adalah input vector (prediktor), $\\bar{w}$ weight, dan $b$ disebut sebagai bias.\n",
    "\n",
    "<p><img src=\"images/Pemodelan_SVM_.png\" alt=\"\" width=\"334\" height=\"360\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Kelebihan Pemodelan SVM</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/hard_margin_svm.png\" style=\"width: 400px; height: 181px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Support Vector Machine: Soft Margin</font></center>\n",
    "<p><img style=\"undefined: undefined;\" src=\"images/6_SVM.jpg\" alt=\"\" /> <img style=\"undefined: undefined;\" src=\"images/svm_opt.png\" alt=\"\" width=\"461\" height=\"163\" /></p>\n",
    "<ul>\n",
    "<li>Diselesaikan dengan \"mudah\" via linear/quadratic programming.</li>\n",
    "<li>Fungsi ini **Convex** sehingga penyelesaiannya menghasilkan nilai Global Optimal.</li>\n",
    "</ul>\n",
    "\n",
    "* **Interpretasi**: Recursive Feature Elimination (RFE) method melihat bentuk kuadrat dari setiap komponen *w* (higher better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">SVM Kernel (trick): $R^m \\rightarrow R^n, n\\geq m$</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/6_SVM_Kernel.jpg\" style=\"height:168px; width:306px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Contoh Fungsi Kernel</font></center>\n",
    "\n",
    "* Misal x = (x1, x2, x3); y = (y1, y2, y3). \n",
    "* dan fungsi pemetaan variabelnya f(x) = (x1², x1x2, x1x3, x2x1, x2², x2x3, x3x1, x3x2, x3²), \n",
    "* maka kernelnya adalah K(x, y ) = <f(x), f(y)> = <x, y>².\n",
    "* Contoh numerik misal x = (1, 2, 3) dan y = (4, 5, 6). maka:\n",
    "* f(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9) <br> f(y) = (16, 20, 24, 20, 25, 30, 24, 30, 36)\n",
    "* <f(x), f(y)> = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024\n",
    "* complicated!... **Menggunakan fungsi kernel perhitungannya bisa disederhanakan**:\n",
    "* K(x, y) = (4 + 10 + 18)² = 32² = 1024\n",
    "* Artinya perhitungan di dimensi yang tinggi dapat dilakukan di dimensi satu via inner product!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Contoh Fungsi Kernel yang Populer</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/Well-Known_Kernels.png\" style=\"width: 400px; height: 208px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Kelebihan dan Kekurangan SVM</font></center>\n",
    "\n",
    "<p><b>Pros</b></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Akurasinya Baik</li>\n",
    "\t<li>Bekerja dengan baik untuk sampel data yang relatif kecil</li>\n",
    "\t<li>Hanya bergantung pada SV ==&gt; meningkatkan efisiensi</li>\n",
    "\t<li>Convex ==&gt; Minimum Global ==&gt; Pasti Konvergen</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Cons</b></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Tidak efisien untuk data yang besar</li>\n",
    "\t<li>Akurasi terkadang rendah untuk multiklasifikasi (sulit mendapatkan hubungan antar kategori di modelnya)</li>\n",
    "\t<li>Tidak robust terhadap noise</li>\n",
    "</ul>\n",
    "\n",
    "Bacaan lebih lanjut:\n",
    "* https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72\n",
    "* Contoh Perhitungan Manual: https://slideplayer.info/slide/3672979/?fbclid=IwAR3Tteg_PbKwkBxV63FGfat3o9UBfHBnjvGHwlyYcrxKTWeb6gfsSpBAQBE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting and evaluate the model\n",
    "dSVM = svm.SVC(C = 10**5, kernel = 'linear')#Misal menggunakan kernel Linear\n",
    "\n",
    "dSVM.fit(df1_train, y1_train)\n",
    "y_SVM1 = dSVM.predict(df1_test)\n",
    "\n",
    "print(confusion_matrix(y1_test, y_SVM1))\n",
    "print(classification_report(y1_test, y_SVM1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The Support Vectors\n",
    "print('index dr SV-nya: ', dSVM.support_)\n",
    "print('Vector Datanya: \\n', dSVM.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Model Weights for interpretations\n",
    "print('w = ',dSVM.coef_)\n",
    "print('b = ',dSVM.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Menggunakan Kernel: http://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "for kernel in ('sigmoid', 'poly', 'rbf', 'linear'):\n",
    "    dSVM = svm.SVC(kernel=kernel)\n",
    "    dSVM.fit(df1_train, y1_train)\n",
    "    y_SVM = dSVM.predict(df1_test)\n",
    "    print(accuracy_score(y1_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dSVM = svm.SVC(C = 10**5, kernel = 'linear')\n",
    "mulai = time.time()\n",
    "scores_svm = cross_val_score(dSVM, df1, y1, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "print(\"Accuracy SVM: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_svm.mean(), scores_svm.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi untuk mengevaluasi & membandingkan model dengan lebih baik lagi\n",
    "df_['SVM'] = scores_svm\n",
    "p = sns.boxplot(data = df_)\n",
    "df_.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Induktif Bias</font></center>\n",
    "\n",
    "<ul>\n",
    "\t<li>Bias penaksiran parameter (statistik)</li>\n",
    "\t<li>Induktif Bias Sample (Machine Learning - Tom Mitchel)</li>\n",
    "\t<li>Induktif Bias Pemilihan Classifier (Statistical Learning Theory - Vapnik)</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"images/inductive_biases_.png\" style=\"width: 600px; height: 153px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/class.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">(Hyper)Parameter Optimization</font></center>\n",
    "\n",
    "* Perbandingan yang baru saja kita lakukan walau sudah CV, namun belum sepenuhnya valid.\n",
    "* Saat membandingkan model, maka kita harus meyakinkan seluruh model mendapatkan parameternya yang optimal.\n",
    "\n",
    "<img alt=\"\" src=\"images/hyper-parameter_tunning.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "file = 'data/diabetes_data.csv'\n",
    "\n",
    "try:\n",
    "    # Local jupyter notebook, assuming \"file\" is in the \"data\" directory\n",
    "    data = pd.read_csv(file, names=names)\n",
    "except:\n",
    "    # it's a google colab... create folder data and then download the file from github\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/{file}\n",
    "    data = pd.read_csv(file, names=names)\n",
    "    \n",
    "print(data.shape, set(data['class']))\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split Train-Test\n",
    "\n",
    "X = data.values[:,:8]  # Slice data (perhatikan disini struktur data adalah Numpy Array)\n",
    "Y = data.values[:,8]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=99)\n",
    "\n",
    "print(set(Y), x_train.shape, x_test.shape, sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Kita Jalankan Terlebih Dahulu dengan \"Default Parameter\"</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "kNN = neighbors.KNeighborsClassifier()\n",
    "gnb = GaussianNB()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm_ = svm.SVC()\n",
    "\n",
    "Models = [('Regresi Logistik', clf), ('k-NN',kNN), ('Naive Bayes',gnb), ('Decision Tree', dt), ('Random Forest', rf), ('SVM', svm_)]\n",
    "Scores = {}\n",
    "for model_name, model in tqdm(Models):\n",
    "    Scores[model_name] = cross_val_score(model, x_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "dt = pd.DataFrame.from_dict(Scores)\n",
    "ax = sns.boxplot(data=dt, ax=ax)\n",
    "for m, s in Scores.items():\n",
    "    print(m, list(s)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Hyperparameter Optimization</font></center>\n",
    "\n",
    "<ul>\n",
    "<li>Misal akan dicontohkan dua algoritma (model) yang sudah kita bahas sebelumnya: k-NN dan SVM</li>\n",
    "<li>Sebagai latihan silahkan untuk mencoba HO pada model yang lain.</li>\n",
    "<li>Parameter tiap model di ML berbeda-beda dan nilai optimalnya berbeda pada setiap kasus.</li>\n",
    "</ul>\n",
    "<p><img src=\"images/rand_grid_search.png\" alt=\"\" width=\"811\" height=\"406\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"\" src=\"images/grid_search_workflow.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter optimization pada model kNN menggunakan gridCV\n",
    "kCV = 10\n",
    "metric = 'accuracy'\n",
    "params = {}\n",
    "params['kneighborsclassifier__n_neighbors'] = [1, 3, 5, 10, 15, 20, 25, 30]\n",
    "params['kneighborsclassifier__weights'] = ('distance', 'uniform')\n",
    "\n",
    "pipe = make_pipeline(neighbors.KNeighborsClassifier())\n",
    "optKnn = GridSearchCV(pipe, params, cv=kCV, scoring=metric, verbose=1, n_jobs=-2) #\n",
    "optKnn.fit(x_train, y_train)\n",
    "print(optKnn.best_score_)\n",
    "print(optKnn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh Hyperparameter optimization pada model SVM menggunakan RandomizedSearchCV\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "# Berikut ini contoh bagaimana mengetahui parameter yang dapat kita optimasi.\n",
    "# Gunakan pengetahuan teori/analitik untuk mengoptimasi hanya parameter yang paling penting.\n",
    "pipeSVM = make_pipeline(svm.SVC())\n",
    "print(sorted(pipeSVM.get_params().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimal parameter SVM dengan RandomizedSearch\n",
    "# WARNING cell ini butuh waktu komputasi cukup lama\n",
    "kCV = 10\n",
    "paramsSVM = {}\n",
    "paramsSVM['svc__C'] = [1, 10, 100, 1000] #sp.stats.uniform(scale=100)\n",
    "paramsSVM['svc__gamma'] = [0.1, 0.001, 0.0001, 1, 10]\n",
    "paramsSVM['svc__kernel'] = ['rbf', 'sigmoid', 'linear'] # , 'poly'\n",
    "optSvm = RandomizedSearchCV(pipeSVM, paramsSVM, cv=kCV, scoring=metric, verbose=2, n_jobs=-2) # refit=True, pre_dispatch='2*n_jobs' pre_dispatch min 2* n_jobs\n",
    "optSvm.fit(x_train, y_train)\n",
    "print(optSvm.best_score_)\n",
    "print(optSvm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Selection\n",
    "\n",
    "<img alt=\"\" src=\"images/model_selection.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "kCV = 10\n",
    "# Menggunakan parameter optimal\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors= 20, weights= 'uniform')\n",
    "svm_ = svm.SVC(kernel= 'linear', gamma= 10, C= 10)\n",
    "\n",
    "# Melakukan Cross Validasi\n",
    "models = ['kNN', 'SVM']\n",
    "knn_score = cross_val_score(kNN, x_train, y_train, cv=kCV, scoring='accuracy', n_jobs=-2, verbose=1)\n",
    "svm_score = cross_val_score(svm_, x_train, y_train, cv=kCV, scoring='accuracy', n_jobs=-2, verbose=1)\n",
    "scores = [knn_score, svm_score]\n",
    "\n",
    "data = {m:s for m,s in zip(models, scores)}\n",
    "for name in data.keys():\n",
    "    print(\"Accuracy %s: %0.2f (+/- %0.2f)\" % (name, data[name].mean(), data[name].std() * 2))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "p = sns.boxplot(data=pd.DataFrame(data), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Ensemble Model</font></center>\n",
    "\n",
    "<ul>\n",
    "\t<li>What? a learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions.</li>\n",
    "\t<li>Why? Better prediction, More stable model</li>\n",
    "\t<li>How? Bagging &amp; Boosting</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"images/Ensemble.png\" style=\"width: 500px; height: 213px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">“meta-algorithms” : Bagging & Boosting</font></center>\n",
    "\n",
    "<p><img style=\"undefined: undefined;\" src=\"images/Bagging_VS_Boosting.png\" alt=\"\" width=\"911\" height=\"337\" /></p>\n",
    "\n",
    "* Ensemble https://www.youtube.com/watch?v=Un9zObFjBH0 \n",
    "* Bagging https://www.youtube.com/watch?v=2Mg8QD0F1dQ \n",
    "* Boosting https://www.youtube.com/watch?v=GM3CDQfQ4sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Boosting in ML</font></center>\n",
    "\n",
    "<center><video controls src=\"videos/Boosting.mp4\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Property of Boosting</font></center>\n",
    "<img alt=\"\" src=\"images/Bagging-Boosting_Usage.png\" style=\"width: 500px; height: 281px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">AdaBoost</font></center>\n",
    "<ul>\n",
    "\t<li><a href=\"https://youtu.be/BoGNyWW9-mE?t=70\" target=\"_blank\">https://youtu.be/BoGNyWW9-mE?t=70</a></li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"images/AdaBoost.png\" style=\"width: 400px; height: 332px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Voting (Bagging) di Python\n",
    "# Catatan : Random Forest termasuk Bagging Ensemble (walau modified)\n",
    "# Best practicenya Model yang di ensemble semuanya menggunakan Optimal Parameter\n",
    "\n",
    "kNN = neighbors.KNeighborsClassifier(3)\n",
    "kNN.fit(X_train, Y_train)\n",
    "Y_kNN = kNN.score(X_test, Y_test)\n",
    "\n",
    "DT = tree.DecisionTreeClassifier(random_state=1)\n",
    "DT.fit(X_train, Y_train)\n",
    "Y_DT = DT.score(X_test, Y_test)\n",
    "\n",
    "model = VotingClassifier(estimators=[('k-NN', kNN), ('Decision Tree', DT)], voting='hard')\n",
    "model.fit(X_train,Y_train)\n",
    "Y_Vot = model.score(X_test,Y_test)\n",
    "\n",
    "print('Akurasi k-NN', Y_kNN)\n",
    "print('Akurasi Decision Tree', Y_DT)\n",
    "print('Akurasi Votting', Y_Vot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging juga bisa digunakan di Klasifikasi (ndak hanya Regresi), \n",
    "# tapi kita pakai probabilitas dari setiap kategori\n",
    "T = tree.DecisionTreeClassifier()\n",
    "K = neighbors.KNeighborsClassifier()\n",
    "R = LogisticRegression()\n",
    "\n",
    "T.fit(X_train,Y_train)\n",
    "K.fit(X_train,Y_train)\n",
    "R.fit(X_train,Y_train)\n",
    "\n",
    "y_T=T.predict_proba(X_test)\n",
    "y_K=K.predict_proba(X_test)\n",
    "y_R=R.predict_proba(X_test)\n",
    "\n",
    "Ave = (y_T+y_K+y_R)/3\n",
    "print(Ave[:5]) # Print just first 5\n",
    "prediction = [v.index(max(v)) for v in Ave.tolist()]\n",
    "print(prediction[:5]) # Print just first 5\n",
    "print('Akurasi Averaging', accuracy_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "num_trees = 100\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=33)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Imbalance Data</font></center>\n",
    "\n",
    "* Metric Trap\n",
    "* Akurasi kategori tertentu lebih penting\n",
    "* Contoh kasus\n",
    "<img alt=\"\" src=\"images/imbalance.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Imbalance Learning</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/under-over-sampling.png\" style=\"width: 500px; height: 147px;\" />\n",
    "\n",
    "* Undersampling, Oversampling, Model Based (weight adjustment)\n",
    "* https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "* Plot perbandingan: https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html#sphx-glr-auto-examples-combine-plot-comparison-combine-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = data[\"class\"].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "\n",
    "svm_balanced = svm.SVC(kernel='linear') #WEIGHTED SVM\n",
    "svm_balanced.fit(x_train, y_train)\n",
    "y_SVMb = svm_balanced.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_SVMb))\n",
    "print(classification_report(y_test, y_SVMb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "# x_train, x_test, y_train, y_test\n",
    "\n",
    "svm_balanced = svm.SVC(kernel='linear', class_weight={1: 3}) #WEIGHTED SVM\n",
    "svm_balanced.fit(x_train, y_train)\n",
    "y_SVMb = svm_balanced.predict(x_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_SVMb))\n",
    "print(classification_report(y_test, y_SVMb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of model-based imbalance treatment - SVM\n",
    "from sklearn.datasets import make_blobs\n",
    "n_samples_1, n_samples_2 = 1000, 100\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 0.5]\n",
    "X, y = make_blobs(n_samples=[n_samples_1, n_samples_2],centers=centers,cluster_std=clusters_std,random_state=33, shuffle=False)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10}) #WEIGHTED SVM\n",
    "wclf.fit(X, y)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')# plot the samples\n",
    "ax = plt.gca()# plot the decision functions for both classifiers\n",
    "xlim = ax.get_xlim(); ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)# create grid to evaluate model\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)# get the separating hyperplane\n",
    "a = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-']) # plot decision boundary and margins\n",
    "Z = wclf.decision_function(xy).reshape(XX.shape)# get the separating hyperplane for weighted classes\n",
    "b = ax.contour(XX, YY, Z, colors='r', levels=[0], alpha=0.5, linestyles=['-'])# plot decision boundary and margins for weighted classes\n",
    "plt.legend([a.collections[0], b.collections[0]], [\"non weighted\", \"weighted\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Weighted Decision Tree</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tree.DecisionTreeClassifier(random_state = 33)\n",
    "T.fit(X_train,Y_train)\n",
    "y_DT = T.predict(X_test)\n",
    "print('Akurasi  (Decision tree Biasa) = ', accuracy_score(Y_test, y_DT))\n",
    "print(classification_report(Y_test, y_DT))\n",
    "\n",
    "T = tree.DecisionTreeClassifier(class_weight = 'balanced', random_state = 33)\n",
    "T.fit(X_train,Y_train)\n",
    "y_DT = T.predict(X_test)\n",
    "print('Akurasi  (Weighted Decision tree) = ', accuracy_score(Y_test, y_DT))\n",
    "print(classification_report(Y_test, y_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Studi Kasus (Latihan) ENB2012: Prediksi Penggunaan Energi Gedung</font></center>\n",
    "\n",
    "<img src=\"images/buildings-by-calibrated-simulation.png\" alt=\"\" width=\"503\" height=\"377\" />\n",
    "\n",
    "# <font color=\"green\"> Task</font></center>\n",
    "\n",
    "* Filter data EcoTest dan pilih hanya yang kategori di variabel target muncul min 10 kali (heat-cat)\n",
    "* Lakukan EDA (Preprocessing dan visualisasi dasar)\n",
    "* Tentukan model terbaik (dengan parameter optimal dan cross validasi)\n",
    "* Hati-hati Naive Bayes, Decision Tree dan Random Forest tidak memerlukan one-hot encoding.\n",
    "* Gunakan Metric Micro F1-Score untuk menentukan model terbaiknya.\n",
    "\n",
    "# <font color=\"green\">Optional</font></center>\n",
    "* Coba bandingkan model terbaik diatas dengan model ensemble.\n",
    "* Apakah ada imbalance problem, coba atasi dengan over/under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = \"data/building-energy-efficiency-ENB2012_data.csv\"\n",
    "\n",
    "try: # Running Locally, yakinkan \"file_\" berada di folder \"data\"\n",
    "    data = pd.read_csv(file_, error_bad_lines=False, low_memory = False, encoding='utf8')\n",
    "except: # Running in Google Colab\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/ptpjb/master/{file_}\n",
    "    data = pd.read_csv(file_, error_bad_lines=False, low_memory = False, encoding='utf8')\n",
    "print(data.shape)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawaban Latihan dimulai di cell ini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul 12 - Model Klasifikasi Lanjutan</font></center>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/Meme Deep Learning SVM.jpg\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
