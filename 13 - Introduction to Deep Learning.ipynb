{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"green\"> https://bit.ly/ptpjb-2021-13</font></center>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://bit.ly/ptpjb-2021-13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">13 - Introduction to Neural Network & Deep Learning</font></center>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">tau-data Indonesia</font><br>Taufik Sutanto & Fathu Rahman - 2021</center>\n",
    "<center><a href=\"https://tau-data.id\">https://tau-data.id</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Outline - Introduction to Neural network & Deep Learning</font></center>\n",
    "\n",
    "* Pendahuluan Neural Network\n",
    "* Training Neural Network\n",
    "* Kelebihan dan Kekurangan\n",
    "* Studi Kasus\n",
    "* TensorBoard\n",
    "* Hyper-parameter Tuning\n",
    "* Latihan\n",
    "\n",
    "<img alt=\"\" src=\"images/deep-learning-machine-learning-AI.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/Sejarah_ML_AI.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Sejarah Perkembangan Metode di Machine Learning, Neural network & Deep Learning</font></center>\n",
    "\n",
    "## Sejarah Beberapa Metode di Machine Learning:\n",
    "\n",
    "* Bayesian\t\t: 1763 Thomas Bayes, Statisticians\n",
    "* Regresi\t\t: Abad 19 (~18XX), Francis Galton (biologist)\n",
    "* Decision Tree\t: 1959, William Belson, biologist  (popular oleh R. Quinlan 80-an ID3 & CART oleh )\n",
    "* Perceptron\t\t: 1962, Frank Rosenblatt, psychologist\n",
    "* SVM\t\t: 1963, Vapnik, Mathematics and Statistics.\n",
    "* Neural network\t: 1974, Werbos (backprop), 1990 Hecht-Nielsen (MLP)(setelah perceptron)\n",
    "* Semi-Supervised\t: 1965 Scruder, tapi popular 2008 Zhu (comp scientist)\n",
    "* Ensemble\t\t: 1979, Dasarathy, \n",
    "* Deep learning\t: ...\n",
    "\n",
    "## Sejarah Deep Learning:\n",
    "\n",
    "* Ketika ML (SVM) sedang populer di tahun 2010, beberapa peneliti tetap mendalami NN, diantaranya nama-nama tenar seperti&nbsp;Geoffrey Hinton di the University of Toronto, dan Yann LeCun di New York University.\n",
    "* Deep Learning dengan GPU dimulai di tahun 2011 (Dan Ciresan dari&nbsp; IDSIA-Swiss)\n",
    "* Namun di 2012 baru terkenal karena permasalahan klasifikasi ImageNet (~1,4 juta image dikategorikan ke 1000 kelas) mampu diselesaikan oleh Hinton. Awalnya akurasinya &#39;hanya&#39; ~74% (2011), lalu ~83(2012), dan di anggap telah solved di 2015 dengan akurasi ~96% (Deep Convolutional Neural Network - convnets).\n",
    "* Sejak itu&nbsp;convnets menjadi model dasar computer vision.\n",
    "* Di Kaggle (2016-2017) ada trend untuk data terstruktur biasanya diselesaikan dengan Gradient Boosting (e.g. XGBoost) dan data tidak terstruktur dengan DL (e.g. Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Penantian Lama Aplikasi Teori di Deep learning</font></center>\n",
    "\n",
    "<p>Theory Deep Learning sebenarnya sudah cukup lama ada (dibahas):</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>convolutional neural networks dan backpropagation &mdash; 1989</li>\n",
    "\t<li>The Long Short-Term Memory ( LSTM ) algorithm (timeseries DL)&nbsp;&mdash;&nbsp;1997</li>\n",
    "</ul>\n",
    "\n",
    "<p>Lalu mengapa baru tenar di 2012?</p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Hardware (terutama GPU)</li>\n",
    "\t<li>Dataset (Big Data)</li>\n",
    "\t<li>Perkembangan Algoritma terbaru : Better activation functions, weight-initialization schemes, optimization schemes (e.g.Adam W)</li>\n",
    "</ul>\n",
    "\n",
    "<big><strong>Tapi apa sebenarnya Deep Learning?</strong></big>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Neural network VS Deep Learning</font></center>\n",
    "\n",
    "<p><img src=\"images/5_DeepLearning.png\" alt=\"\" width=\"487\" height=\"549\" /></p>\n",
    "<ul>\n",
    "<li>Yang menjadi pembeda utama DL dengan ML adalah DL \"<em>Learning representations from data</em>\". Misal Word Embedding (bandingkan dengan VSM di Machine Learning).</li>\n",
    "<li>Makna \"Deep\" di DL sendiri bermakna \"successive layers of representations\" biasa juga disebut sebagai&nbsp;<em>layered representations learning</em> atau <em>hierarchical representations learning</em>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\"> Deep Learning & \"Big Data\"</font></center>\n",
    "\n",
    " <img alt=\"\" src=\"images/why_DL.png\" />\n",
    " \n",
    "* Seringnya DL butuh data yang besar untuk memperoleh performa (akurasi) yang baik.\n",
    "* \"Transfer Learning\" di Deep learning diperkenalkan untuk mengatasi hal ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Pendahuluan model Jaringan</font></center>\n",
    "\n",
    "<img src=\"images/intro_nn.JPG\"  style=\"width: 800px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"\" src=\"images/6_JST.JPG\" style=\"height:400px; width:706px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Alur Perhitungan pada Model Jaringan</font></center>\n",
    "\n",
    "<ul>\n",
    "\t<li><img alt=\"\" src=\"images/VG_1.gif\" style=\"width: 250px; height: 270px;\" /></li>\n",
    "\t<li><img alt=\"\" src=\"images/VG_2.gif\" style=\"width: 250px; height: 270px;\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Training Neural Network </font></center>\n",
    "\n",
    "<img src=\"images/cara_kerja_nn.JPG\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Fungsi Aktivasi</font></center>\n",
    "\n",
    "<ul>\n",
    "<li>Fungsi aktivasi adalah fungsi yang memutuskan apakah suatu neuron harus diaktifkan atau tidak berdasarkan hasil perhitungan kombinasi linear antara variabel input dengan masing-masing bobotnya. Selain itu fungsi aktivasi bisa berfungsi untuk merubah kombinasi linear tersebut menjadi output yang non linear</li>\n",
    "<li>Terdapat beberapa <em>activation function</em>, di antaranya sebagai berikut:</li>\n",
    "</ul>\n",
    "<p><img style=\"undefined: undefined;\" src=\"images/act_func.png\" alt=\"\" width=\"524\" height=\"142\" /> <img style=\"undefined: undefined;\" src=\"images/6_JST_Actv.png\" alt=\"\" width=\"518\" height=\"427\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Contoh Fungsi tanh memetakan [-Inf, Inf] ke [-1, 1]</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/tanh_act.gif\" style=\"width: 800px; height: 317px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Fungsi Aktivasi Sigmoid yang bisa digunakan untuk menginat dan melupakan</font></center>\n",
    "\n",
    "<ul>\n",
    "\t<li>Fungsi sigmoid mirip dengan tanh, namun intervalnya adalah [0, 1].</li>\n",
    "\t<li>Semakin dekat ke 0 ==&gt; melupakan (forget): informasi tidak relevan.</li>\n",
    "\t<li>Semakin dekat ke 1 ==&gt; mengingat: informasi relevan/penting.</li>\n",
    "\t<li><img alt=\"\" src=\"images/sigmoid.gif\" style=\"width: 800px; height: 317px;\" /></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Tanpa fungsi aktivasi apa yang akan terjadi?</font></center>\n",
    "\n",
    "* Tanpa fungsi aktivasi, weights bisa membesar tak berbatas ketika iterasinya berjalan\n",
    "\n",
    "<p><img alt=\"\" src=\"images/tanpa_tanh.gif\" style=\"width: 800px; height: 106px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Dengan Fungsi Aktivasi, nilai weights selalu terbatas (misal) di -1 dan 1, namun tingkat kepentingan weight tetap terjaga.</font></center>\n",
    "\n",
    "* Perhatikan nilai weight yang pertama\n",
    "<img alt=\"\" src=\"images/dgn_tanh.gif\" style=\"width: 800px; height: 106px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Contoh Cara Kerja/Perhitungan Neural Network</font></center>\n",
    "\n",
    "<center><video align=\"center\" controls src=\"videos/neural network.mp4\"  width=\"800\"/></center>\n",
    "\n",
    "link: https://youtu.be/o20mBWPHGEw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">\"Toy Data\" Contoh Perhitungan Neural Network (Back Propagation)</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/NN-BP_step_1.png\" style=\"width: 600px; height: 358px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/NN-BP_step_2.png\" style=\"width: 600px; height: 348px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_3.png\" style=\"width: 600px; height: 313px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_4.png\" style=\"width: 600px; height: 305px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_5.png\" style=\"width: 600px; height: 305px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/Loss_function_neural_network_deep_learning.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Memilih Fungsi Aktivasi dan Fungsi Loss</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/memilih_loss_dan_activation.png\" style=\"width: 600px; height: 368px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Peran Optimizer</font></center>\n",
    "\n",
    "\n",
    "<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 500px\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td><img alt=\"\" src=\"images/contours_evaluation_optimizers.gif\" /></td>\n",
    "\t\t\t<td><img alt=\"\" src=\"images/saddle_point_evaluation_optimizers.gif\" /></td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "Optimizer : \n",
    "<a href=\"http://ruder.io/optimizing-gradient-descent/\" target=\"_blank\">http://ruder.io/optimizing-gradient-descent/&nbsp;</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Loss function dan Error</font></center>\n",
    "\n",
    "<p><img alt=\"\" src=\"images/low-high-bias-variance.png\" style=\"width: 600px; height: 244px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Loss Function, Optimizer, & metric</font></center>\n",
    "\n",
    "<ol>\n",
    "\t<li><strong>Loss function (objective function)</strong> &mdash; fungsi yang akan di minimize. Hasilnya merepresentasikan tingkat sukses pada setiap iterasi.<br />\n",
    "\t<a href=\"https://keras.io/losses/\" target=\"_blank\">https://keras.io/losses/&nbsp;</a></li>\n",
    "\t<li><strong>Optimizer&nbsp;</strong>&mdash; Berfungsi untuk menentukan bagaimana (weights) di network akan di update berdasarkan loss-functionnya. (e.g. variasi dari SGD)<br />\n",
    "\t<a href=\"https://keras.io/optimizers/\" target=\"_blank\">https://keras.io/optimizers/</a></li>\n",
    "\t<li><strong>Metrics&nbsp;</strong>&mdash; Satuan evaluasi<br />\n",
    "\t<a href=\"https://keras.io/metrics/\" target=\"_blank\">https://keras.io/metrics/</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img alt=\"\" src=\"images/NN-BP_step_6.png\" style=\"width: 600px; height: 304px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_7.png\" style=\"width: 600px; height: 305px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_8.png\" style=\"width: 600px; height: 303px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"images/NN-BP_step_9.png\" style=\"width: 600px; height: 301px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Multiclassification di Model Jaringan</font></center>\n",
    "\n",
    "<img alt=\"\" src=\"images/Multiclass_ANN.png\" style=\"width: 600px; height: 468px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Empirical Analysis Parameter di Model Jaringan</font></center>\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "<p>Tensorflow PlayGround: <strong><a href=\"https://goo.gl/3rcnc9\" target=\"_blank\" rel=\"nofollow noopener\">https://goo.gl/3rcnc9</a></strong></p>\n",
    "</li>\n",
    "<li>\n",
    "<p>Memahami \"Bias\" di Model jaringan: Mengapa dengan fungsi linear bisa membentuk \"boundary\" yang melengkung (kurva)?</p>\n",
    "<strong><a href=\"http://s.id/j6i\" target=\"_blank\" rel=\"nofollow noopener\">http://s.id/j6i</a></strong>\n",
    "\n",
    "</li>\n",
    "</ul>\n",
    "<p><img src=\"images/tensorflow_playground.png\" width=\"638\" height=\"380\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"undefined: undefined;\" src=\"images/6_tipe_NN.png\" alt=\"\" width=\"618\" height=\"1050\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Deep learning (Popular) Frameworks</font></center>\n",
    "\n",
    "<img src=\"images/deep-learning-frameworks.jpg\" style=\"width: 800px\"/>\n",
    "\n",
    "* https://morioh.com/p/ae3bdc889d0c\n",
    "* https://marutitech.com/top-8-deep-learning-frameworks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Kelebihan dan Kekurangan</font></center>\n",
    "\n",
    "<img src=\"images/pros and cons.jpeg\" style=\"width: 600px\"/><br>\n",
    "\n",
    "image source: \n",
    "- https://slidetodoc.com/neural-networks-and-support-vector-machines-outline-neural/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Penerapan Neural Network</font></center>\n",
    "\n",
    "<br>\n",
    "<center><video align=\"center\" controls src=\"videos/neural_network_in_life.MP4\"/></center>\n",
    "\n",
    "source: https://www.youtube.com/watch?v=me3QEYPsFWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Studi Kasus</font></center> \n",
    "\n",
    "- Sebagai ilustrasi, kita gunakan data konsumsi energi tiap rumah untuk membuat model neural network\n",
    "- Data tersebut terdiri dari 504 baris dan 4 kolom, kolom tersebut di antaranya yaitu:\n",
    "1. jumlah ruangan\n",
    "2. jumlah penghuni\n",
    "3. luas bangunan\n",
    "4. banyaknya energi listrik yang digunakan dalam satuan KWh per bulan\n",
    "\n",
    "<img src=\"images/data_energi.JPG\"/>\n",
    "\n",
    "- Data tersebut merupakan hasil modifikasi dari data boston housing (link: https://www.kaggle.com/c/boston-housing)\n",
    "- Model neural network yang akan dibuat bertujuan untuk memprediksi kolom energi listrik berdasarkan kolom lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modul Standar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Konsumsi Energi\n",
    "- Data konsumsi energi diimport menggunakan pandas\n",
    "- karena format datanya csv maka untuk mengimportnya menggunakan `pd.read_csv()`\n",
    "- setelah diimport dan simpan dalam variabel energi, kita coba lihat 5 data teratas menggunakan `energi.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = 'data/konsumsi_energi.csv'\n",
    "try: # Running Locally\n",
    "    energi = pd.read_csv(file_)\n",
    "except: # Running in Google Colab\n",
    "    !mkdir data\n",
    "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/ptpjb/main/{file_}\n",
    "    energi = pd.read_csv(file_)\n",
    "energi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(energi, y_vars='listrik')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dari hasil visualisasi data terlihat bahwa terdapat keanehan pada data.\n",
    "- Hal tersebut dikarenakan data yang digunakan bukan data sebenarnya.\n",
    "- Tetapi coba kita tetap gunakan sebagai contoh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melihat Statistika Deskriptif dari Data\n",
    "- Sebelum melakukan pembuatan model, sebaiknya dilakukan analisa terhadap statistika deskriptif dari data\n",
    "- Dari statistika deskriptif tersebut, kita dapat meilhat range dari data dan ukuran pusat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "energi.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dari statistika deskriptif di atas terlihat perbedaan range antara jumlah_keluarga, jumlah_ruangan dengan luas_bangunan dan listrik\n",
    "- Karena perbedaan range tersebut, nanti kita akan lakukan **feature scalling** menggunakan **MinMaxScaler** agar range dari seluruh data tersebut berada di antara 0 dan 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menentukan variabel target dan variabel input\n",
    "Karena tujuan kita adalah memprediksi kolom listrik berdasarkan kolom lainnya, maka:\n",
    "- kita tetapkan kolom listrik sebagai variabel target (y) \n",
    "- dan kolom lainnya sebagai variabel input (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = energi[['listrik']].values\n",
    "X = energi.drop(columns=['listrik']).values\n",
    "\n",
    "# Check the shape of training data\n",
    "print(X.shape,y.shape)\n",
    "print(type(y),type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perhatikan bahwa code di atas menggunakan `.values` saat menetapkan variabel y dan X\n",
    "- Hal tersebut dilakukan untuk merubah tipe data dataframe menjadi numpy array\n",
    "- Tensorflow sebenarnya dapat memproses tipe data dataframe, namun tipe data numpy array akan lebih cepat diproses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "<img src=\"images/cross_validation.png\">\n",
    "\n",
    "- Split data dilakukan agar model yang telah dilatih dapat dievaluasi kemampuannya.\n",
    "- Kita gunakan **train_test_split** dari modul **sklearn** untuk melakukan split data\n",
    "- **train_test_split** tersebut melakukan split data dengan **stratified sampling**\n",
    "- Kita juga akan melakukan **cross validation** menggunakan data train sehingga pastikan data train yang digunakan cukup besar.\n",
    "- Pada contoh ini kita gunakan 80% data train dan 20% data test\n",
    "- **random_state** ditetapkan berupa bilangan integer agar hasil split data yang dilakukan secara acak selalu sama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print('Banyak data train:', len(X_train))\n",
    "print('Banyak data test :', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scalling\n",
    "\n",
    "- Perbedaan range antara variabel-variabel yang digunakan akan menyulitkan proses pelatihan model neural network\n",
    "- Selain itu range yang besar juga dapat menyebabkan suatu ketika nilai loss function sangat besar sehingga proses pelatihan model neural network tidak mencapai nilai minimum\n",
    "- Oleh karena itu perlu dilakukan **feature scalling** menggunakan **MinMaxScaler** agar seluruh data memiliki range yang sama yaitu dari 0 sampai 1\n",
    "- Rumus MinMaxScaler:\n",
    "# <center> $x^*=\\frac{x-x_{min}}{x_{max}-x_{min}}$</center>\n",
    "\n",
    "<img src=\"images/minmax.png\" width=\"500\"/>\n",
    "\n",
    "- MinMaxScaler difit pada data train agar dapat digunakan kembali pada data test maupun data observasi baru\n",
    "- MinMaxScaler diterapkan secara terpisah antara variabel target dan input karena ketika ingin memprediksi variabel target dengan data observasi baru, data tersebut hanya terdiri dari variabel input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(X_train)\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "X_train_scaled = scaler1.transform(X_train)\n",
    "X_test_scaled = scaler1.transform(X_test)\n",
    "y_train_scaled = scaler2.transform(y_train)\n",
    "y_test_scaled = scaler2.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Menggunakan Tensorflow dan Keras\n",
    "- tensorflow: https://www.tensorflow.org/overview\n",
    "- keras: https://keras.io/about/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalasi Lokal GPU Support (TensorFlow-CUDA) untuk model Deep Learning. \n",
    "\n",
    "* Link ini akan membantu menyesuaikan versi CUDA dan CudNN yang tepat untuk semua versi TensorFlow.  Hati-hati!!!.... requirement CUDA dan CudNN berbeda antara Linux & Windows (Walau versi tensorflow-nya sama!!!).\n",
    "* Berikut Versi Keras-TensorFlow yang bersesuaiannya: https://docs.floydhub.com/guides/environments/\n",
    "Download Cuda dan CudNN yang bersesuaian (seringnya BUKAN versi terakhir) dari sini (need to register):\n",
    "* https://developer.nvidia.com/rdp/cudnn-archive\n",
    "* https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "* Setelah install Cuda/Cudnn, jika compiler terinstall dengan baik, maka perintah **pip install --upgrade tensorflow-gpu** bisa digunakan di terminal/command prompt.\n",
    "\n",
    "[Linux]:  https://www.tensorflow.org/install/source#tested_build_configurations \n",
    "\n",
    "[Windows]:  https://www.tensorflow.org/install/source_windows \n",
    "\n",
    "Untuk \"PyTorch\" cenderung lebih mudah: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colaboratory\n",
    "\n",
    "* Free with GPU (& TPU) support (Max run ~ 10jam)\n",
    "* Login dengan Username dan password Google\n",
    "* Kunjungi https://colab.research.google.com\n",
    "* New Python 3 Notebook, rename/save Notebook \n",
    "* Runtime>Change runtime type and select GPU as Hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, matplotlib.pyplot as plt; warnings.simplefilter('ignore')\n",
    "import pickle, numpy as np, tensorflow as tf, time, os, matplotlib.pyplot as plt, seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow import keras    \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version = \", tf.__version__)\n",
    "if tf.test.is_built_with_cuda():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    print(\"CUDA enabled TF, Num GPUs:\", len(physical_devices), physical_devices) \n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struktur neural network di keras API\n",
    "- **Sequential model**\n",
    "\n",
    "Sequential model memungkinkan kita untuk membuat model layer demi layer secara berurutan. Untuk membuat variabel Sequential model dilakukan sebagai berikut:\n",
    "\n",
    "`from keras.models import Sequential`<br>\n",
    "`model = Sequential()`\n",
    "- **Dense layer**\n",
    "\n",
    "Dense layer membuat fully connected layer dengan neuron-neuron yang terhubung pada layer sebelumnya. Pada dense layer ini kita dapat menentukan berapa banyak neuron dan fungsi aktivasi apa yang digunakan. Sebagai contoh untuk menambahkan Dense layer dengan neuron sebanyak 32 dan fungsi aktivasi sigmoid pada Sequential model dilakukan sebagai berikut:\n",
    "\n",
    "`model = Sequential()`<br>\n",
    "`model.add(Dense(32, input_dim=3, activation='sigmoid'))`\n",
    "\n",
    "input_dim berfungsi untuk menentukan banyaknya variabel input dan hanya ditentukan pada layer pertama.\n",
    "- **Dropout layer**\n",
    "\n",
    "Dropout layer adalah layer penting untuk mengurangi over-fitting dalam model neural network. Dropout layer akan mengurangi kompleksitas model neural network dengan mengurangi jumlah neuron secara acak sehingga hal ini dapat mencegah over-fitting. persentase jumlah neuron yang dikurangi dapat dilakukan dengan menentukan nilai dropout antara 0 sampai 1.\n",
    "\n",
    "<img src=\"images/dropout.jpg\" width=\"400\"/>\n",
    "\n",
    "image source: https://www.tech-quantum.com/implementing-drop-out-regularization-in-neural-networks/\n",
    "\n",
    "Untuk melakukan dropout pada layer sebelumnya sebesar 20% dapat dilakukan sebagai berikut:\n",
    "\n",
    "`model = Sequential()`<br>\n",
    "`model.add(Dense(32, input_dim=3, activation='sigmoid'))`<br>\n",
    "`model.add(Dropout(0.2))`\n",
    "- **Compiler**\n",
    "\n",
    "Setelah membangun arsitektur neural network, kita perlu memilih tiga hal lagi pada tahap \"kompilasi\": \n",
    "1. **Loss Function**: adalah bagaimana neural network dapat mengukur seberapa besar kesalahan pelatihan yang dilakukan pada data trainnya, dengan demikian model dapat meminimumkan kesalahan tersebut. Beberapa loss function pada Keras API dapat pilih tergantung pada permasalahannya\n",
    "\n",
    "<img src=\"images/keras_losses.JPG\"/>\n",
    "\n",
    "image source: https://keras.io/api/losses/\n",
    "\n",
    "Pada contoh ini permasalahannya adalah regresi karena variabel targetnya berupa variabel kontinu sehingga kita akan memilih loss function untuk regresi. Loss function yang sering digunakan pada permasalahan regresi adalah **Mean squared error (MSE)**. MSE berfungsi untuk menghitung rata-rata error kuadrat antara nilai prediksi dan nilai sebenarnya.\n",
    "<img src=\"images/mse1.png\"/>\n",
    "\n",
    "image source: https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "\n",
    "2. **Optimizer**: adalah algoritma untuk meminimalkan loss function dengan memperbarui bobot-bobot pada model neural network secara iteratif. terdapat bebrapa optimizer pada Keras, di antaranya sebagai berikut:\n",
    "\n",
    "<img src=\"images/keras_optimizer.JPG\"/>\n",
    "\n",
    "Dari beberapa optimizer di atas, yang paling sering digunakan adalah Adam Optimizer. Pemilihan optimizer tersebut akan mempengaruhi lamanya proses pelatihan model untuk mencapai loss function yang minimum. berikut disajikan perbandingan proses meminimalkan loss function dengan beberapa optimzer\n",
    "<img src=\"images/Keras_Optimizers-min.gif\" width=\"300\"/>\n",
    "\n",
    "image source: https://machinelearningknowledge.ai/keras-optimizers-explained-with-examples-for-beginners/\n",
    "\n",
    "3. **Metric**: adalah fungsi yang digunakan untuk menilai kinerja model yang telah dibuat. Fungsi metric mirip dengan loss function. Hanya saja tidak semua fungsi metric dapat dijadikan loss function (misal akurasi, karena kita tidak ingin meminimalkan akurasi). Sebaliknya seluruh loss function dapat dijadikan metric karena nilai loss function yang kecil dapat mengindikasi bahwa model cukup baik. Berikut metric-metric yang ada di Keras:\n",
    "<img src=\"images/keras_metric.jpg\"/>\n",
    "\n",
    "Pada contoh ini kita akan gunakan **Mean Absolute Error (MAE)** sebagai metric. MAE berfungsi untuk menghitung rata-rata selisih antara nilai prediksi dan nilai sebenarnya.\n",
    "<img src=\"images/mae.jpg\" width = \"700\"/>\n",
    "\n",
    "Untuk menambahkan compiler pada arsitektur neural network yang telah dibuat dapat dilakukan sebagai berikut:\n",
    "\n",
    "`model = Sequential()`<br>\n",
    "`model.add(Dense(32, input_dim=3, activation='sigmoid'))`<br>\n",
    "`model.add(Dropout(0.2))`<br>\n",
    "`model.compile(loss='mse', optimizer='adam', metrics=['mae'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Model Neural Network \n",
    "### 1. Import Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Membuat Fungsi Model Neural Network\n",
    "Dalam membuat model neural network tidak harus berupa fungsi, namun dengan membuat fungsi model neural network akan lebih mudah dalam merubah parameter-parameternya.\n",
    "\n",
    "Fungsi model neural network yang akan dibuat terdiri:\n",
    "- input layer dengan 3 feature (jumlah_ruangan, jumlah_penghuni, luas_bangunan)\n",
    "- 1 Dense hidden layer\n",
    "- Dropout antara Dense hidden layer dan Dense output layer\n",
    "- Dense output layer dengan 1 neuron (prediksi jumlah penggunaan energi)\n",
    "- loss function yang digunakan adalah Mean Squared Error (MSE)\n",
    "- optimizer yang digunakan adalah adam\n",
    "- metric yang digunakan adalah Mean Absolute Error (MAE)\n",
    "\n",
    "Parameter-parameter yang dijadikan sebagai input dari fungsi tersebut adalah:\n",
    "- neurons: banyaknya neuron pada Dense layer (default = 10)\n",
    "- activation: fungsi aktivasi yang digunakan (default = 'relu')\n",
    "- dropout: persentase dropout (default = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons=10, activation='relu', dropout=0.2):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=3, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Membuat Model\n",
    "\n",
    "Misalkan kita akan membuat model dengan parameter-parameter input sebagai berikut:\n",
    "- neuron = 32\n",
    "- activation = 'sigmoid'\n",
    "- dropout = 0.1\n",
    "\n",
    "Maka kita dapat membuat model neural network sebagai berikut:\n",
    "\n",
    "`model = create_model(32,'sigmoid',0.1)`\n",
    "\n",
    "Atau jika ingin membuat model dengan input default:\n",
    "\n",
    "`model = create_model()`\n",
    "\n",
    "Kita dapat melihat arsitektur model yang kita buat dengan cara berikut:\n",
    "\n",
    "`model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(32,'sigmoid',0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training Model\n",
    "Training model dapat dilakukan sebagai berkut:\n",
    "\n",
    "`history = model.fit(X_train_scaled,y_train_scaled, batch_size=32, epochs=100, validation_split=0.1, verbose=2)`\n",
    "\n",
    "Perhatikan parameter epochs dan batch_size\n",
    "\n",
    "<img src=\"images/epoch_batch_size.jpeg\" width= \"400\"/>\n",
    "\n",
    "image source: https://jerryan.medium.com/batch-size-a15958708a6\n",
    "\n",
    "Stochastic Gradient Descent, Clearly Explained!!!: https://www.youtube.com/watch?v=vMh0zPT0tLI\n",
    "\n",
    "\n",
    "**Parameter-parameter model.fit()**\n",
    "- bacth_size: adalah banyaknya sampel pada satu kali training yang digunakan untuk memperbarui seluruh bobot\n",
    "- epochs: adalah banyaknya proses training dengan seluruh sampel.\n",
    "- validation_split: adalah persentase data yang digunakan sebagai data validasi\n",
    "- verbose: adalah opsi untuk menampilkan proses training (0 = silent, 1 = progress bar, 2 = one line per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "history = model.fit(X_train_scaled,y_train_scaled, epochs=100, batch_size=32, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat melihat grafik loss function MSE dan metric MAE terhadap epoch untuk melihat performa model kita dengan cara sebagai berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafik loss function MSE\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('loss function MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafik metric MAE\n",
    "\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('metric MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perhatikan kedua grafik di atas**. Kita dapat lihat kurang lebih pada epoch ke 40 nilai loss function dan metric sudah cukup stabil. sehingga sebenarnya kita cukup menentukan **epochs = 40**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "**Bagaimana menentukan nilai epochs?**\n",
    "\n",
    "### Perhatikan gambar berikut!\n",
    "\n",
    "<img src=\"images/Early-stopping-method.png\" width=\"600\"/>\n",
    "\n",
    "- Training seharusnya dihentikan saat epoch berada pada garis optimal seperti gambar di atas. Yaitu ketika nilai loss function pada data validasi mulai naik (sebelum terjadi overfitting) ataupun bisa juga ketika nilainya cukup stabil seperti pada kasus model kita.\n",
    "- Hal tersebut dapat dilakukan dengan menambahkan Early Stopping yang memiliki parameter sebagai berikut:\n",
    "1. monitor: nilai yang diamati, biasanya adalah nilai loss function pada data validasi (bisa juga metric validasi)\n",
    "2. mode: terdapat 3 mode yaitu \"min\" (training berhenti ketika nilai yang diamati berhenti turun), \"max\" (training berhenti ketika nilai yang diamati berhenti naik), dan \"auto\"\n",
    "3. min_delta: besarnya selisih mutlak yang tidak dianggap mengalami perbaikan (naik/turun)\n",
    "4. patience: banyaknya epoch setelah nilai yang diamati tidak mengalami perbaikan\n",
    "5. verbose: adalah opsi untuk menampilkan epoch ke berapa saat proses training berhenti (0 = silent, 1 = display)\n",
    "\n",
    "**Mari kita coba membuat model menggunakan Early Stopping dengan parameter-parameter berikut**\n",
    "- monitor = 'val_loss' (nilai yang diamati adalah loss function pada data validasi)\n",
    "- mode = \"min\" (mode \"min\" karena kita mengharapkan val_loss selalu turun)\n",
    "- min_delta = 0.01 (ketika val_loss turun kurang dari 0.01 dianggap tidak terjadi penurunan, maka training berhenti)\n",
    "- patience = 10 (ketika tidak terjadi penurunan, maka training berhenti setelah 10 epoch lagi dilakukan)\n",
    "- verbose = 1 (menampilkan epoch ke berapa saat proses training berhenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(32,'sigmoid',0.1)\n",
    "\n",
    "# Early Stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = \"min\", min_delta = 0.01, patience = 10, verbose = 1)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X_train_scaled,y_train_scaled,\n",
    "                    epochs=100, batch_size=32,\n",
    "                    validation_split=0.1, callbacks = [es],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafik loss function MSE\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('loss function MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perhatikan Grafik di Atas!!!\n",
    "Walaupun kita menetapkan epoch = 100, proses training terhenti pada epoch ke 15 karena kita menggunakan **Early Stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluasi Model dengan Data Test\n",
    "\n",
    "- Sebelum melakukan evaluasi model dengan data test, kita akan melakukan prediksi pada data test dengan cara berikut:\n",
    "\n",
    "`y_pred = model.predict(X_test_scaled)`\n",
    "\n",
    "- Karena nilai prediksi di atas masih dalam scala MinMaxScaler (scaler2), maka kita perlu membalikkannya menggunakan fungsi inverse_transform() sebagai berikut:\n",
    "\n",
    "`y_pred = scaler2.inverse_transform(y_pred)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred = scaler2.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setelah melakukan prediksi barulah kita melakukan evaluasi terhadap nilai prediksi tersebut menggunakan metric yang digunakan yaitu MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (MAE) test data\n",
    "mae = np.mean(np.abs(y_test-y_pred))\n",
    "print('MAE data test sebesar:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah Nilai MAE Tersebut Bagus???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Melihat boxplot dari nilai error mutlak**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error = np.abs(y_test-y_pred)\n",
    "\n",
    "sns.boxplot(y = abs_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Melihat range data test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('minimum y_test', y_test.min())\n",
    "print('maksimum y_test', y_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">TensorBoard</font></center> \n",
    "\n",
    "- Dalam machine learning, untuk meningkatkan suatu model kita sering kali harus bisa mengukurnya. \n",
    "- TensorBoard adalah alat yang menyediakan pengukuran dan visualisasi yang diperlukan dalam proses kerja machine learning.\n",
    "- Hal ini memungkinkan untuk mengamati eksperimen yang dilakukan seperti loss function dan metric evaluation, memvisualisasikan graf model, memproyeksikan embeddings ke ruang dimensi yang lebih rendah, dan banyak lagi.\n",
    "- link :https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "Untuk menggunakan TensorBoard pada model neural network, dapat dilakukan dengan cara berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(32,'sigmoid',0.1)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y-%m-%d;%H-%M-%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = \"min\", min_delta = 0.01, patience = 10, verbose = 1)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X_train_scaled,y_train_scaled,\n",
    "                    epochs=100, batch_size=32,\n",
    "                    validation_split=0.1, callbacks = [es, tensorboard_callback],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Hyper-parameter Tuning</font></center> \n",
    "\n",
    "## Berapa Banyak Neuron yang Diperlukan? Fungsi Aktivasi Apa yang Harus Digunakan? Berapa Persen Dropout yang Ditentukan?\n",
    "\n",
    "- Pertanyaan di atas dapat dijawab dengan melakukan hyper-parameter tuning atau melakukan beberapa percobaan dan memilih hasil yang terbaik\n",
    "- Hyper-parameter tuning dapat lakukan menggunakan fungsi GridSearchCV dari modul sklearn\n",
    "\n",
    "<img src=\"images/grid_search.png\" width=\"500\"/><br>\n",
    "- Namun untuk membuat model neural network menggunakan GridSearchCV, kita harus menggunakan fungsi model neural network dan dimasukan ke dalam KerasRegressor\n",
    "- Selain fungsi model neural network, parameter-parameter yang dimasukan pada model.fit() seperti contoh sebelumnya juga dimasukan ke dalam KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Model Neural Network dengan Hyper-parameter Tuning\n",
    "### 1. Import Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Membuat Model dengan KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = \"min\", min_delta = 0.005, patience = 5, verbose = 0)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=500, validation_split=0.1, batch_size=32, callbacks=[es], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Menentukan parameter-parameter\n",
    "- Pada contoh ini kita akan melakukan percobaan terhadap jumlah neuron, fungsi aktivasi, dan persentase dropout.\n",
    "- ketiga parameter tersebut beserta nila-nilai yang ingin digunakan kemudian dimasukan pada variabel **param_grid** dengan tipe data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "neurons = [32, 64, 128]\n",
    "activation = ['relu','sigmoid','tanh']\n",
    "dropout=[0.1, 0.2, 0.3]\n",
    "param_grid = dict(neurons=neurons, activation=activation, dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Membuat Model dengan GridSearchCV\n",
    "Model dengan GridSearchCV dibuat dengan memasukan beberapa parameter yaitu:\n",
    "- estimator: model yang ingin dilakukan gridsearch\n",
    "- param_grid: parameter yang ingin diuji\n",
    "- n_jobs: Jumlah pekerjaan untuk dijalankan secara paralel. (-1 artinya menggunakan seluruh core processor)\n",
    "- cv: banyaknya k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Model dengan GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Memilih Parameter Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari Hasil Training menggunakan GridSearchCV, kita peroleh:\n",
    "- parameter terbaiknya adalah: {'activation': 'relu', 'dropout': 0.3, 'neurons': 128}\n",
    "- Rata-rata Loss Function dari hasil Cross Validation adalah 0.047091 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model terbaik dari hasil GridSearchCV kita masukan ke dalam variabel best_model dengan cara \n",
    "\n",
    "`best_model = grid_result.best_estimator_.model` \n",
    "\n",
    "- Kemudian coba kita lihat grafik loss function MSE dan metric MAE terhadap epoch untuk melihat performa model terbaik kita dengan cara sebagai berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_.model\n",
    "history = best_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafik loss function MSE\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('loss function MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafik metric MAE\n",
    "\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('metric MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluasi Model dengan Data Test\n",
    "Dengan cara yang sama seperti pada contoh sebelumnya kita akan menghitung MAE pada data test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_pred = scaler2.inverse_transform(y_pred)\n",
    "\n",
    "abs_error = np.abs(y_test-y_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE) test data\n",
    "mae = np.mean(abs_error)\n",
    "print('MAE data test sebesar:', mae)\n",
    "\n",
    "sns.boxplot(y = abs_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah Nilai MAE Tersebut Lebih Bagus dari Sebelumnya???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membandingkan Nilai MAE dari Hasil Regresi Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg_pred = reg.predict(X_test)\n",
    "\n",
    "abs_error = np.abs(y_test-reg_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE) test data dari model regresi\n",
    "mae = np.mean(abs_error)\n",
    "print('MAE data test sebesar:', mae)\n",
    "\n",
    "sns.boxplot(y = abs_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Latihan</font></center>\n",
    "\n",
    "## Dengan menggunakan data konsumsi energi tiap rumah di atas, buatlah model neural network untuk memprediksi kolom listrik berdasarkan input kolom luas_bangunan dengan ketentuan sebagai berikut!\n",
    "\n",
    "1. Arsitektur neural network terdiri dari:\n",
    "- Input layer, hidden layer (Dense layer, Dropout, Dense layer), Dense ouput layer\n",
    "- Fungsi aktivasi yang digunakan pada kedua Dense layer adalah 'ReLu'\n",
    "- Persentase Dropout yang digunakan 10%\n",
    "- Compiler: loss='mse', optimizer='adam', metrics=['mae']\n",
    "\n",
    "2. Model dibuat menggunakan GridSearchCV dengan paramater yang diuji:\n",
    "- banyaknya neuron pada Dense layer pertama = [16,32,64]\n",
    "- banyaknya neuron pada Dense layer kedua = [10,20,30]\n",
    "\n",
    "3. Early Stopping diterapkan sehingga training berhenti pada saat epoch yang optimal\n",
    "\n",
    "4. Lakukan evaluasi pada data test dan simpulkan hasil evaluasi tersebut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> Akhir Modul 13 Introduction to Network Model and Tensorflow</font></center>\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme tensors flow node to node.jpeg\" style=\"height: 400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
