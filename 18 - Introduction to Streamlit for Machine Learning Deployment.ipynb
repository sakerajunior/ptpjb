{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"red\"> https://bit.ly/ptpjb-2021-18</font>\n",
    "# <center><font color=\"blue\">18 - Introduction to Streamlit for Machine Learning Deployment</font>\n",
    "\n",
    "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
    "\n",
    "## <center><font color=\"blue\">tau-data Indonesia</font><br>(C) Taufik Sutanto - 2021</center>\n",
    "<center><a href=\"https://tau-data.id\">https://tau-data.id</a> ~ <a href=\"mailto:taufik@tau-data.id\">taufik@tau-data.id</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/meme_deploy.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/alur_ml_deploy.jpeg\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Deploy Machine Learning Models?\n",
    "\n",
    "- Deployment model machine learning adalah proses untuk membuat model tersedia dalam tahap produksi.\n",
    "- Sehingga model terbaik yang telah dibuat dapat digunakan dalam bentuk aplikasi web, perangkat lunak perusahaan, atau API dengan menyediakan data observasi baru untuk menghasilkan prediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Tools\n",
    "\n",
    "<img src=\"images/webframeworks_python.jpg\" width=\"700\"/>\n",
    "<img src=\"images/heroku_logo.png\" width=\"400\"/>\n",
    "<img src=\"images/streamlit_logo.png\" width=\"400\"/>\n",
    "\n",
    "image source:\n",
    "- https://www.activestate.com/blog/the-top-10-python-frameworks-for-web-development/\n",
    "- https://www.keyzex.com/2018/09/apa-itu-heroku-cara-deploy-di-heroku.html?m=1\n",
    "- https://ichi.pro/id/streamlit-merevolusi-pembuatan-aplikasi-data-248940993548562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit\n",
    "link: https://streamlit.io/\n",
    "<img src=\"images/streamlit.JPG\" width=\"700\"/>\n",
    "- **Streamlit** Streamlit adalah sebuah framework berbasis Python dan bersifat open-source yang dibuat untuk memudahkan dalam membangun apikasi web di bidang data science dan machine learning yang interaktif.\n",
    "- Salah satu hal menarik dari framework ini adalah kita tidak perlu mengetahui banyak hal tentang teknologi web development. \n",
    "- Kita tidak perlu dipusingkan tentang bagaiamana mengatur tampilan website dengan CSS, HTML, atau Javascript. \n",
    "- Untuk menggunakan Streamlit, kita cukup memiliki modal dasar mengetahui bahasa Python saja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contoh aplikasi web yang dibuat di streamlit\n",
    "- **Sistem Deteksi Objek Real-Time:** Aplikasi ini dibangun dengan menggunakan dataset Self Driving Car Udacity. Aplikasi tersebut mampu mendeteksi objek secara real-time, menggunakan algoritma deteksi objek YOLO di backend yang terjalin dengan Streamlit di frontend.\n",
    "\n",
    "<img src=\"images/streamlit_app_1.gif\"/>\n",
    "\n",
    "- **Face GAN Explorer:** Aplikasi ini mampu menghasilkan wajah fotorealistik dan dibangun dengan TensorFlow menggunakan Nvidia's Progressive Growing of GANs dan metode Transparent Latent-space GAN milik Shaobo Guan untuk menyetel karakteristik wajah keluaran.\n",
    "\n",
    "<img src=\"images/streamlit_app_2.gif\"/>\n",
    "\n",
    "- **Peramban Data Geografis untuk NYC:** Aplikasi ini menggunakan data penjemputan Uber dari New York City untuk secara interaktif memvisualisasikan penjemputan uber dan perjalanan penumpang melintasi NYC.\n",
    "\n",
    "\n",
    "<img src=\"images/streamlit_app_3.gif\"/>\n",
    "\n",
    "image source: https://ichi.pro/id/streamlit-merevolusi-pembuatan-aplikasi-data-248940993548562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Anomaly Detection App\n",
    "\n",
    "kita akan coba bagaimana melakukan deployment sederhana menggunakan streamlit pada model anomaly detection yang telah kita buat. hasil deployment yang akan kita buat akan memiliki tampilan seperti berikut:\n",
    "\n",
    "<img src=\"images/streamlit app.JPG\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persiapan\n",
    "**Lakukan instalasi streamlit pada command prompt atau anaconda prompt:**\n",
    "- `> pip install streamlit`\n",
    "- `> streamlit hello`\n",
    "\n",
    "**Menyiapkan file yang diperlukan:**\n",
    "- model anomaly detection yang telah dibuat\n",
    "- feature scaling yang digunakan\n",
    "- data untuk mencoba aplikasi anomaly detection\n",
    "\n",
    "file-file di atas dapat dipersiapkan pada modul jupyter notebook **14 - Deep Learning ~ LSTM** dan di simpan pada folder streamlit.\n",
    "\n",
    "**Membuat text-file python**\n",
    "kemudian pada folder deployment tersebut kita buat text-file dengan format `.py` untuk menuliskan code deployment menggunakan streamlit.\n",
    "\n",
    "<img src=\"images/text-file 1.JPG\"/>\n",
    "<img src=\"images/text-file 2.JPG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code in Python\n",
    "\n",
    "Pada file `LSTM_AD.py` kita tuliskan code seperti di bawah ini. kemudian kita akan bahas kegunaannya baris-perbaris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The App.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create sliding window\n",
    "def sliding_window(data, window_size):\n",
    "    sub_seq, next_values = [], []\n",
    "    for i in range(len(data)-window_size):\n",
    "        sub_seq.append(data[i:i+window_size])\n",
    "        next_values.append(data[i+window_size])\n",
    "    X = np.stack(sub_seq)\n",
    "    y = np.array(next_values)\n",
    "    return X,y\n",
    "\n",
    "window_size = 30\n",
    "\n",
    "# Load the model from the file\n",
    "model = keras.models.load_model('anomaly_detection')\n",
    "\n",
    "# load the scaler\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "threshold = 527.8798828125\n",
    "\n",
    "st.write(\"\"\"\n",
    "# LSTM Anomaly Detection App for Web Traffic Data\n",
    "\"\"\")\n",
    "\n",
    "st.write(\"\"\"\n",
    "### Data format and must be greater than 30 timestamps\n",
    "| timestamp  | value   |\n",
    "| -----------|:-------:|\n",
    "| 1          | 10      |\n",
    "| 2          | 7       |\n",
    "| 3          | 17      |\n",
    "\"\"\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose a file\", type='csv')\n",
    "\n",
    "if uploaded_file is not None:\n",
    "\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    df['scaled'] = scaler.transform(df[['value']])\n",
    "    \n",
    "    X, y = sliding_window(df[['scaled']].values, window_size)\n",
    "    \n",
    "    predict = scaler.inverse_transform(model.predict(X))\n",
    "    y = scaler.inverse_transform(y)\n",
    "    \n",
    "    abs_error = np.abs(y - predict)\n",
    "    \n",
    "    test_anomaly = pd.DataFrame()\n",
    "    test_anomaly['timestamp'] = df['timestamp'][window_size:]\n",
    "    test_anomaly['value'] = df['value'][window_size:]\n",
    "    test_anomaly['abs_error'] = abs_error\n",
    "    test_anomaly['anomaly_hat'] = 0\n",
    "    test_anomaly.loc[test_anomaly['abs_error'] >= threshold, 'anomaly_hat'] = 1\n",
    "    \n",
    "    anomalies = test_anomaly.loc[test_anomaly['anomaly_hat'] == 1]\n",
    "\n",
    "    st.write(\"Visualize Detected Anomalies from Data\")  \n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_anomaly['timestamp'], y=test_anomaly['value'], name='value'))\n",
    "    fig.add_trace(go.Scatter(x=anomalies['timestamp'], y=anomalies['value'], mode='markers', name='Anomaly'))\n",
    "    fig.update_layout(showlegend=True, title='Detected anomalies')\n",
    "    st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import modul/library yang diperlukan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membuat fungsi sliding window serta menentukan window size sesuai dengan model anomaly detection yang digunakan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sliding window\n",
    "def sliding_window(data, window_size):\n",
    "    sub_seq, next_values = [], []\n",
    "    for i in range(len(data)-window_size):\n",
    "        sub_seq.append(data[i:i+window_size])\n",
    "        next_values.append(data[i+window_size])\n",
    "    X = np.stack(sub_seq)\n",
    "    y = np.array(next_values)\n",
    "    return X,y\n",
    "\n",
    "window_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memuat model anomaly detection dan feature scaling serta menentukan threshold dari hasil model anomaly detection yang dibuat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "model = keras.models.load_model('anomaly_detection')\n",
    "\n",
    "# load the scaler\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "threshold = 527.8798828125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Menampilkan header dan contoh format data yang benar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write(\"\"\"\n",
    "# LSTM Anomaly Detection App for Web Traffic Data\n",
    "\"\"\")\n",
    "\n",
    "st.write(\"\"\"\n",
    "### Data format and must be greater than 30 timestamps\n",
    "| timestamp  | value   |\n",
    "| -----------|:-------:|\n",
    "| 1          | 10      |\n",
    "| 2          | 7       |\n",
    "| 3          | 17      |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi st.write() dari modul streamlit salah satu fungsinya adalah untuk menampilkan sesuatu dalam format `markdown`. Agar dapat menulis `markdown` dengan beberapa baris maka kita gunakan tanda kutip tiga `(\"\"\" <markdown> \"\"\")`\n",
    "\n",
    "Dari code di atas kita akan peroleh tampilan sebagai berikut:\n",
    "\n",
    "<img src=\"images/header.JPG\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membuat tombol upload**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = st.file_uploader(\"Choose a file\", type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi st.file_uploader() dari modul streamlit berfungsi untuk membuat tombol upload. Argumen `\"Choose a file\"` dan `type='csv'` berarti kita menentukan judul pada tombol upload dan tipe file yang dapat diupload.\n",
    "\n",
    "Dari code di atas kita akan peroleh tampilan sebagai berikut:\n",
    "\n",
    "<img src=\"images/file upload.JPG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memproses data yang diupload**\n",
    "\n",
    "Setelah data diupload kita gunakan code `if uploaded_file is not None:` untuk memperoses data tersebut dengan langkah-langkah seperti pada modul jupyter notebook **14 - Deep Learning ~ LSTM**\n",
    "\n",
    "untuk menampilkan grafik kita gunakan st.plotly_chart() dari modul streamlit dengan argumen `fig` yaitu variabel grafik dari modul plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_file is not None:\n",
    "\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    df['scaled'] = scaler.transform(df[['value']])\n",
    "    \n",
    "    X, y = sliding_window(df[['scaled']].values, window_size)\n",
    "    \n",
    "    predict = scaler.inverse_transform(model.predict(X))\n",
    "    y = scaler.inverse_transform(y)\n",
    "    \n",
    "    abs_error = np.abs(y - predict)\n",
    "    \n",
    "    test_anomaly = pd.DataFrame()\n",
    "    test_anomaly['timestamp'] = df['timestamp'][window_size:]\n",
    "    test_anomaly['value'] = df['value'][window_size:]\n",
    "    test_anomaly['abs_error'] = abs_error\n",
    "    test_anomaly['anomaly_hat'] = 0\n",
    "    test_anomaly.loc[test_anomaly['abs_error'] >= threshold, 'anomaly_hat'] = 1\n",
    "    \n",
    "    anomalies = test_anomaly.loc[test_anomaly['anomaly_hat'] == 1]\n",
    "\n",
    "    st.write(\"Visualize Detected Anomalies from Data\")  \n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_anomaly['timestamp'], y=test_anomaly['value'], name='value'))\n",
    "    fig.add_trace(go.Scatter(x=anomalies['timestamp'], y=anomalies['value'], mode='markers', name='Anomaly'))\n",
    "    fig.update_layout(showlegend=True, title='Detected anomalies')\n",
    "    st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari code di atas kita akan peroleh tampilan sebagai berikut setelah file diupload:<br>\n",
    "<img src=\"images/uploaded file.JPG\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menjalankan Aplikasi Web Streamlit\n",
    "Aplikasi web streamlit dapat dijalankan di **lokal** atau bisa  melalui **share streamlit**\n",
    "- **Menjalankan aplikasi web streamlit di lokal**\n",
    "1. Buka command prompt atau anaconda prompt dan arahkan ke direktori penyimpanan file aplikasi web streamlit (misal: LSTM_AD.py) berada\n",
    "\n",
    "<img src=\"images/streamlit_local12.JPG\"/>\n",
    "<img src=\"images/streamlit_local1.JPG\"/>\n",
    "\n",
    "2. pada cmd, ketik: `streamlit run LSTM_AD.py`\n",
    "\n",
    "<img src=\"images/streamlit_local2.JPG\"/>\n",
    "\n",
    "3. kemudian tekan `Enter` dan streamlit akan membuka aplikasi web melalui browser\n",
    "\n",
    "<img src=\"images/streamlit_local3.JPG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Menjalankan aplikasi web streamlit melalui share streamlit**\n",
    "\n",
    "**Persiapan:**\n",
    "1. Memiliki akun GitHub dan sign up pada laman https://streamlit.io/sharing-sign-up\n",
    "2. Kemudian hubungkan akun streamlit dengan GitHub (memerlukan 1-2 hari kerja)\n",
    "3. siapkan repository GitHub yang berisikan file-file seperti saat dijalankan di lokal ditambah text-file bernama requirements.txt yang berisikan library python berserta versi yang digunakan seperti gambar berikut.\n",
    "\n",
    "<img src=\"images/requirements_streamlit.JPG\"/>\n",
    "\n",
    "**Langkah-langkah:**\n",
    "1. setelah persiapan di atas dilakukan, sign in pada laman https://share.streamlit.io/\n",
    "2. klik New app\n",
    "\n",
    "<img src=\"images/streamlit_share1.JPG\"/>\n",
    "\n",
    "3. isikan repository untuk deployment dan main file pathnya adalah nama file aplikasi web streamlit. kemudian klik deploy\n",
    "\n",
    "<img src=\"images/streamlit_share2.JPG\"/>\n",
    "\n",
    "4. maka aplikasi web akan diproses dan jika sudah maka hasilnya seperti gambar berikut\n",
    "<img src=\"images/streamlit_share3.JPG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latihan\n",
    "\n",
    "<center><h3>Buatlah aplikasi web model regresi dari tabel berikut menggunakan streamlit sehingga aplikasi web yang dihasilkan seperti gambar berikut!</h3><center/>\n",
    "    \n",
    "<center><h3>Kemudian deploy aplikasi web tersebut ke share streamlit!</h3><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penutup\n",
    "Masih banyak lagi cara untuk deployment model machine learning menggunakan streamlit. kita dapat mengeksplor lagi dokumentasi streamlit pada link berikut: https://docs.streamlit.io/en/stable/api.html ataupun melihat hasil deployment yang telah dibagikan pada link berikut: https://streamlit.io/gallery. Selain itu dapat juga didesain terlebih dahulu deployment yang ingin dilakukan agar lebih terarah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Akhir Modul 18 - Introduction to Streamlit for Machine Learning Deployment\n",
    "    \n",
    "<hr />\n",
    "<img alt=\"\" src=\"images/meme-cartoon/meme deployment.jpg\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
