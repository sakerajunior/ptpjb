{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "18 - Introduction to Streamlit for Machine Learning Deployment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNRwiWC9hnNe"
      },
      "source": [
        "# <center><font color=\"red\"> https://bit.ly/ptpjb-2021-18</font>\n",
        "# <center><font color=\"blue\">18 - Introduction to Streamlit for Machine Learning Deployment</font>\n",
        "\n",
        "<center><img alt=\"\" src=\"images/cover_ptpjb_2021.png\"/></center> \n",
        "\n",
        "## <center><font color=\"blue\">tau-data Indonesia</font><br>(C) Taufik Sutanto - 2021</center>\n",
        "<center><a href=\"https://tau-data.id\">https://tau-data.id</a> ~ <a href=\"mailto:taufik@tau-data.id\">taufik@tau-data.id</a></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY1HO5LQhnNi"
      },
      "source": [
        "# 18 - Introduction to Streamlit for Machine Learning Deployment\n",
        "\n",
        "<img src=\"images/streamlit.jpg\"/>\n",
        "\n",
        "link: https://streamlit.io/\n",
        "\n",
        "<br>\n",
        "<div style=\"text-align: center\">\n",
        "    <video controls src=\"videos/Streamlit.mp4\" width=\"700\" >\n",
        "<div/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeadioNJhnNj"
      },
      "source": [
        "## Deploy Anomaly Detection App\n",
        "\n",
        "kita akan coba bagaimana melakukan deployment sederhana menggunakan streamlit pada model anomaly detection yang telah kita buat. hasil deployment yang akan kita buat akan memiliki tampilan seperti berikut:\n",
        "\n",
        "<img src=\"images/streamlit app.jpg\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fBziTU9hnNj"
      },
      "source": [
        "## Persiapan\n",
        "**Lakukan instalasi streamlit pada command prompt (cmd):**\n",
        "- `> pip install streamlit`\n",
        "- `> streamlit hello`\n",
        "\n",
        "**Menyiapkan file yang diperlukan:**\n",
        "- model anomaly detection yang telah dibuat\n",
        "- feature scaling yang digunakan\n",
        "- data untuk mencoba aplikasi anomaly detection\n",
        "\n",
        "file-file di atas dapat dipersiapkan pada modul jupyter notebook **14 - Deep Learning ~ LSTM** dan di simpan pada folder deployment.\n",
        "\n",
        "**Membuat text-file python**\n",
        "kemudian pada folder deployment tersebut kita buat text-file dengan format `.py` untuk menuliskan code deployment menggunakan streamlit.\n",
        "\n",
        "<img src=\"images/text-file 1.jpg\"/>\n",
        "<img src=\"images/text-file 2.jpg\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRfqqZs3hnNk"
      },
      "source": [
        "## Code in Python\n",
        "\n",
        "Pada file `LSTM_AD.py` kita tuliskan code seperti di bawah ini. kemudian kita akan bahas kegunaannya baris-perbaris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEyqXpkAhnNk"
      },
      "source": [
        "\"\"\"The App.\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import keras\n",
        "import pickle\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create sliding window\n",
        "def sliding_window(seq, window_size):\n",
        "    sub_seq, next_values = [], []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        sub_seq.append(seq[i:i+window_size])\n",
        "        next_values.append([seq[i+window_size]])\n",
        "    X = np.array(sub_seq)\n",
        "    y = np.array(next_values)\n",
        "    return X,y\n",
        "\n",
        "window_size = 10\n",
        "\n",
        "# Load the model from the file\n",
        "model = keras.models.load_model('anomaly_detection')\n",
        "\n",
        "# load the scaler\n",
        "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
        "\n",
        "threshold = 18.97461056150496\n",
        "\n",
        "st.write(\"\"\"\n",
        "# LSTM Anomaly Detection App for Web Traffic Data\n",
        "\"\"\")\n",
        "\n",
        "st.write(\"\"\"\n",
        "### Data format and must be greater than 10 timestamps\n",
        "| timestamp  | value   |\n",
        "| -----------|:-------:|\n",
        "| 1          | 10      |\n",
        "| 2          | 7       |\n",
        "| 3          | 17      |\n",
        "\"\"\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a file\", type='csv')\n",
        "\n",
        "if uploaded_file is not None:\n",
        "\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    df['scaled'] = scaler.transform(df[['value']])\n",
        "    \n",
        "    X, y = sliding_window(df['scaled'], window_size)\n",
        "    \n",
        "    # Reshape input to be [samples, time steps, features]\n",
        "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "    \n",
        "    predict = scaler.inverse_transform(model.predict(X))\n",
        "    y = scaler.inverse_transform(y)\n",
        "    \n",
        "    abs_error = np.abs(y - predict)\n",
        "\n",
        "    test_score_df = pd.DataFrame()\n",
        "    test_score_df['timestamp'] = df['timestamp'][window_size:]\n",
        "    test_score_df['value'] = df['value'][window_size:]\n",
        "    test_score_df['loss'] = abs_error\n",
        "    test_score_df['threshold'] = threshold\n",
        "    test_score_df['anomaly_hat'] = 0\n",
        "    test_score_df.loc[test_score_df.loss >= test_score_df.threshold, 'anomaly_hat'] = 1\n",
        "    \n",
        "    anomalies = test_score_df.loc[test_score_df['anomaly_hat'] == 1]\n",
        "\n",
        "    st.write(\"Visualize Detected Anomalies from Data\")  \n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=test_score_df['timestamp'], y=test_score_df['value'], name='value'))\n",
        "    fig.add_trace(go.Scatter(x=anomalies['timestamp'], y=anomalies['value'], mode='markers', name='Anomaly'))\n",
        "    fig.update_layout(showlegend=True, title='Detected anomalies')\n",
        "    st.plotly_chart(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZjxkHZXhnNl"
      },
      "source": [
        "**Import modul/library yang diperlukan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvGapMGDhnNm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import keras\n",
        "import pickle\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNxgv5TkhnNm"
      },
      "source": [
        "**Membuat fungsi sliding window serta menentukan window size sesuai dengan model anomaly detection yang digunakan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNfnZ888hnNm"
      },
      "source": [
        "# Create sliding window\n",
        "def sliding_window(seq, window_size):\n",
        "    sub_seq, next_values = [], []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        sub_seq.append(seq[i:i+window_size])\n",
        "        next_values.append([seq[i+window_size]])\n",
        "    X = np.array(sub_seq)\n",
        "    y = np.array(next_values)\n",
        "    return X,y\n",
        "\n",
        "window_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slAlHwZ6hnNn"
      },
      "source": [
        "**Memuat model anomaly detection dan feature scaling serta menentukan threshold dari hasil model anomaly detection yang dibuat**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG0wYa-yhnNn"
      },
      "source": [
        "# Load the model from the file\n",
        "model = keras.models.load_model('anomaly_detection')\n",
        "\n",
        "# load the scaler\n",
        "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
        "\n",
        "threshold = 18.209396362304688"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MtgyHDPhnNo"
      },
      "source": [
        "**Menampilkan header dan contoh format data yang benar**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca-knF_7hnNo"
      },
      "source": [
        "st.write(\"\"\"\n",
        "# LSTM Anomaly Detection App for Web Traffic Data\n",
        "\"\"\")\n",
        "\n",
        "st.write(\"\"\"\n",
        "### Data format and must be greater than 10 timestamps\n",
        "| timestamp  | value   |\n",
        "| -----------|:-------:|\n",
        "| 1          | 10      |\n",
        "| 2          | 7       |\n",
        "| 3          | 17      |\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhAIHcnBhnNo"
      },
      "source": [
        "Fungsi st.write() dari modul streamlit berfungsi untuk menampilkan sesuatu dalam format `html`. Agar dapat menulis bahasa `html` dengan beberapa baris maka kita gunakan tanda kutip tiga `(\"\"\" <html> \"\"\")`\n",
        "\n",
        "Dari code di atas kita akan peroleh tampilan sebagai berikut:\n",
        "\n",
        "<img src=\"images/header.jpg\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW6PTuS9hnNo"
      },
      "source": [
        "**Membuat tombol upload**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWGW8hDKhnNp"
      },
      "source": [
        "uploaded_file = st.file_uploader(\"Choose a file\", type='csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efrlksn0hnNp"
      },
      "source": [
        "Fungsi st.file_uploader() dari modul streamlit berfungsi untuk membuat tombol upload. Argumen `\"Choose a file\"` dan `type='csv'` berarti kita menentukan judul pada tombol upload dan tipe file yang dapat diupload.\n",
        "\n",
        "Dari code di atas kita akan peroleh tampilan sebagai berikut:\n",
        "\n",
        "<img src=\"images/file upload.jpg\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjjxRx6WhnNp"
      },
      "source": [
        "**Memproses data yang diupload**\n",
        "\n",
        "Setelah data diupload kita gunakan code `if uploaded_file is not None:` untuk memperoses data tersebut dengan langkah-langkah seperti pada modul jupyter notebook **14 - Deep Learning ~ LSTM**\n",
        "\n",
        "untuk menampilkan grafik kita gunakan st.plotly_chart() dari modul streamlit dengan argumen `fig` yaitu variabel grafik dari modul plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RctFNhh5hnNp"
      },
      "source": [
        "if uploaded_file is not None:\n",
        "\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    df['scaled'] = scaler.transform(df[['value']])\n",
        "    \n",
        "    X, y = sliding_window(df['scaled'], window_size)\n",
        "    \n",
        "    # Reshape input to be [samples, time steps, features]\n",
        "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "    \n",
        "    predict = scaler.inverse_transform(model.predict(X))\n",
        "    y = scaler.inverse_transform(y)\n",
        "    \n",
        "    abs_error = np.abs(y - predict)\n",
        "\n",
        "    test_score_df = pd.DataFrame()\n",
        "    test_score_df['timestamp'] = df['timestamp'][window_size:]\n",
        "    test_score_df['value'] = df['value'][window_size:]\n",
        "    test_score_df['loss'] = abs_error\n",
        "    test_score_df['threshold'] = threshold\n",
        "    test_score_df['anomaly_hat'] = 0\n",
        "    test_score_df.loc[test_score_df.loss >= test_score_df.threshold, 'anomaly_hat'] = 1\n",
        "    \n",
        "    anomalies = test_score_df.loc[test_score_df['anomaly_hat'] == 1]\n",
        "\n",
        "    st.write(\"Visualize Detected Anomalies from Data\")  \n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=test_score_df['timestamp'], y=test_score_df['value'], name='value'))\n",
        "    fig.add_trace(go.Scatter(x=anomalies['timestamp'], y=anomalies['value'], mode='markers', name='Anomaly'))\n",
        "    fig.update_layout(showlegend=True, title='Detected anomalies')\n",
        "    st.plotly_chart(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLGbCkhYhnNp"
      },
      "source": [
        "Dari code di atas kita akan peroleh tampilan sebagai berikut setelah file diupload:<br>\n",
        "<img src=\"images/uploaded file.jpg\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxkyN16EhnNq"
      },
      "source": [
        "## Penutup\n",
        "Masih banyak lagi cara untuk deployment model machine learning menggunakan streamlit. kita dapat mengeksplor lagi dokumentasi streamlit pada link berikut: https://docs.streamlit.io/en/stable/api.html ataupun melihat hasil deployment yang telah dibagikan pada link berikut: https://streamlit.io/gallery. Selain itu dapat juga didesain terlebih dahulu deployment yang ingin dilakukan agar lebih terarah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq3wN0JVhnNq"
      },
      "source": [
        "# <center><font color=\"blue\">Akhir Modul 18 - Introduction to Streamlit for Machine Learning Deployment\n",
        "    \n",
        "<hr />\n",
        "<img alt=\"\" src=\"images/meme-cartoon/meme deployment.jpg\" />"
      ]
    }
  ]
}